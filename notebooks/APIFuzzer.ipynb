{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "source": [
    "# Fuzzing APIs\n",
    "\n",
    "So far, we have always generated _system input_, i.e. data that the program as a whole obtains via its input channels.  However, we can also generate inputs that go directly into individual functions, gaining flexibility and speed in the process.  In this chapter, we explore the use of grammars to synthesize code for function calls, which allows you to generate _program code that very efficiently invokes functions directly._  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bookutils import YouTubeVideo\n",
    "YouTubeVideo('CC1VvOGkzm8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You have to know how grammar fuzzing work, e.g. from the [chapter on grammars](Grammars.ipynb).\n",
    "* We make use of _generator functions_, as discussed in the [chapter on fuzzing with generators](GeneratorGrammarFuzzer.ipynb).\n",
    "* We make use of probabilities, as discussed in the [chapter on fuzzing with probabilities](ProbabilisticGrammarFuzzer.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Synopsis\n",
    "<!-- Automatically generated. Do not edit. -->\n",
    "\n",
    "To [use the code provided in this chapter](Importing.ipynb), write\n",
    "\n",
    "```python\n",
    ">>> from fuzzingbook.APIFuzzer import <identifier>\n",
    "```\n",
    "\n",
    "and then make use of the following features.\n",
    "\n",
    "\n",
    "This chapter provides *grammar constructors* that are useful for generating _function calls_.\n",
    "\n",
    "The grammars are [probabilistic](ProbabilisticGrammarFuzzer.ipynb) and make use of [generators](GeneratorGrammarFuzzer.ipynb), so use `ProbabilisticGeneratorGrammarFuzzer` as a producer.\n",
    "\n",
    "```python\n",
    ">>> from GeneratorGrammarFuzzer import ProbabilisticGeneratorGrammarFuzzer\n",
    "```\n",
    "`INT_GRAMMAR`, `FLOAT_GRAMMAR`, `ASCII_STRING_GRAMMAR` produce integers, floats, and strings, respectively:\n",
    "\n",
    "```python\n",
    ">>> fuzzer = ProbabilisticGeneratorGrammarFuzzer(INT_GRAMMAR)\n",
    ">>> [fuzzer.fuzz() for i in range(10)]\n",
    "['0', '-49', '0', '67', '1', '0', '0', '0', '0', '-2']\n",
    ">>> fuzzer = ProbabilisticGeneratorGrammarFuzzer(FLOAT_GRAMMAR)\n",
    ">>> [fuzzer.fuzz() for i in range(10)]\n",
    "['-9',\n",
    " '413',\n",
    " '9.15',\n",
    " '143.9e-359',\n",
    " '38894e0',\n",
    " '6.9777',\n",
    " 'inf',\n",
    " '-320',\n",
    " 'inf',\n",
    " '5']\n",
    ">>> fuzzer = ProbabilisticGeneratorGrammarFuzzer(ASCII_STRING_GRAMMAR)\n",
    ">>> [fuzzer.fuzz() for i in range(10)]\n",
    "['\"tHnz+t`v?ypW;x\"',\n",
    " '\"!jua\"',\n",
    " '\"\"',\n",
    " '\"v\"',\n",
    " '\">/ AUo[-P[dD\"',\n",
    " '\"R\"',\n",
    " '\"{Y\\'=j\\\\ay@L\"',\n",
    " '\"W5\\\\\"3GS>bLb^t7k[_Bekxh]G=31\"',\n",
    " '\"]X$of2nk9?Z9[F\"',\n",
    " '\"{!0C+/B*!CL6fDpmQ7NKG\"']\n",
    "```\n",
    "`int_grammar_with_range(start, end)` produces an integer grammar with values `N` such that `start <= N <= end`:\n",
    "\n",
    "```python\n",
    ">>> int_grammar = int_grammar_with_range(100, 200)\n",
    ">>> fuzzer = ProbabilisticGeneratorGrammarFuzzer(int_grammar)\n",
    ">>> [fuzzer.fuzz() for i in range(10)]\n",
    "['114', '170', '156', '184', '182', '200', '121', '142', '169', '164']\n",
    "```\n",
    "`float_grammar_with_range(start, end)` produces a floating-number grammar with values `N` such that `start <= N <= end`.\n",
    "\n",
    "```python\n",
    ">>> float_grammar = float_grammar_with_range(100, 200)\n",
    ">>> fuzzer = ProbabilisticGeneratorGrammarFuzzer(float_grammar)\n",
    ">>> [fuzzer.fuzz() for i in range(10)]\n",
    "['153.59386400810718',\n",
    " '177.63331685788444',\n",
    " 'inf',\n",
    " '166.06737261414125',\n",
    " 'inf',\n",
    " '175.4077192176283',\n",
    " '122.85504078272784',\n",
    " '118.58583496612496',\n",
    " '190.94575151189315',\n",
    " '177.6900227724756']\n",
    "```\n",
    "All such values can be immediately used for testing function calls:\n",
    "\n",
    "```python\n",
    ">>> from math import sqrt\n",
    ">>> fuzzer = ProbabilisticGeneratorGrammarFuzzer(int_grammar)\n",
    ">>> call = \"sqrt(\" + fuzzer.fuzz() + \")\"\n",
    ">>> call\n",
    "'sqrt(125)'\n",
    ">>> eval(call)\n",
    "11.180339887498949\n",
    "```\n",
    "These grammars can also be composed to form more complex grammars. `list_grammar(object_grammar)` returns a grammar that produces lists of objects as defined by `object_grammar`.\n",
    "\n",
    "```python\n",
    ">>> int_list_grammar = list_grammar(int_grammar)\n",
    ">>> fuzzer = ProbabilisticGeneratorGrammarFuzzer(int_list_grammar)\n",
    ">>> [fuzzer.fuzz() for i in range(5)]\n",
    "['[140, 102, 136, 163, 105, 111, 160, 102, 107, 168, 150]',\n",
    " '[154, 180, 107, 120]',\n",
    " '[154, 174]',\n",
    " '[174, 137, 191, 151, 157, 115, 175, 184, 134]',\n",
    " '[125, 166]']\n",
    ">>> some_list = eval(fuzzer.fuzz())\n",
    ">>> some_list\n",
    "[104, 184, 101, 114, 140]\n",
    ">>> len(some_list)\n",
    "5\n",
    "```\n",
    "In a similar vein, we can construct arbitrary further data types for testing individual functions programmatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## Fuzzing a Function\n",
    "\n",
    "Let us start with our first problem: How do we fuzz a given function?  For an interpreted language like Python, this is pretty straight-forward.  All we need to do is to generate _calls_ to the function(s) we want to test.  This is something we can easily do with a grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "As an example, consider the `urlparse()` function from the Python library.  `urlparse()` takes a URL and decomposes it into its individual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import bookutils.setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse('https://www.fuzzingbook.com/html/APIFuzzer.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see how the individual elements of the URL – the _scheme_ (`\"http\"`), the _network location_ (`\"www.fuzzingbook.com\"`), or the path (`\"//html/APIFuzzer.html\"`) are all properly identified.  Other elements (like `params`, `query`, or `fragment`) are empty, because they were not part of our input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test `urlparse()`, we'd want to feed it a large set of different URLs.  We can obtain these from the URL grammar we had defined in the [\"Grammars\"](Grammars.ipynb) chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import URL_GRAMMAR, is_valid_grammar, START_SYMBOL\n",
    "from Grammars import opts, extend_grammar, Grammar\n",
    "from GrammarFuzzer import GrammarFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fuzzer = GrammarFuzzer(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    url = url_fuzzer.fuzz()\n",
    "    print(urlparse(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can easily test any Python function – by setting up a scaffold that runs it.  How would we proceed, though, if we wanted to have a test that can be re-run again and again, without having to generate new calls every time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizing Code\n",
    "\n",
    "The \"scaffolding\" method, as sketched above, has an important downside: It couples test generation and test execution into a single unit, disallowing running both at different times, or for different languages.  To decouple the two, we take another approach: Rather than generating inputs and immediately feeding this input into a function, we _synthesize code_ instead that invokes functions with a given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if we generate the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = \"urlparse('http://www.cispa.de/')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can execute this string as a whole (and thus run the test) at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To systematically generate such calls, we can again use a grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR: Grammar = {\n",
    "    \"<call>\":\n",
    "        ['urlparse(\"<url>\")']\n",
    "}\n",
    "\n",
    "# Import definitions from URL_GRAMMAR\n",
    "URLPARSE_GRAMMAR.update(URL_GRAMMAR)\n",
    "URLPARSE_GRAMMAR[\"<start>\"] = [\"<call>\"]\n",
    "\n",
    "assert is_valid_grammar(URLPARSE_GRAMMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grammar creates calls in the form `urlparse(<url>)`, where `<url>` comes from the \"imported\" URL grammar.  The idea is to create many of these calls and to feed them into the Python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this grammar for fuzzing and synthesizing calls to `urlparse)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_fuzzer = GrammarFuzzer(URLPARSE_GRAMMAR)\n",
    "urlparse_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as above, we can immediately execute these calls.  To better see what is happening, we define a small helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function_name(arg[0], arg[1], ...) as a string\n",
    "def do_call(call_string):\n",
    "    print(call_string)\n",
    "    result = eval(call_string)\n",
    "    print(\"\\t= \" + repr(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = urlparse_fuzzer.fuzz()\n",
    "do_call(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `urlparse()` were a C function, for instance, we could embed its call into some (also generated) C function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR: Grammar = {\n",
    "    \"<cfile>\": [\"<cheader><cfunction>\"],\n",
    "    \"<cheader>\": ['#include \"urlparse.h\"\\n\\n'],\n",
    "    \"<cfunction>\": [\"void test() {\\n<calls>}\\n\"],\n",
    "    \"<calls>\": [\"<call>\", \"<calls><call>\"],\n",
    "    \"<call>\": ['    urlparse(\"<url>\");\\n']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR.update(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR[\"<start>\"] = [\"<cfile>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_grammar(URLPARSE_C_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_fuzzer = GrammarFuzzer(URLPARSE_C_GRAMMAR)\n",
    "print(urlparse_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizing Oracles\n",
    "\n",
    "In our `urlparse()` example, both the Python as well as the C variant only check for _generic_ errors in `urlparse()`; that is, they only detect fatal errors and exceptions.  For a full test, we need to set up a specific *oracle* as well that checks whether the result is valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plan is to check whether specific parts of the URL reappear in the result – that is, if the scheme is `http:`, then the `ParseResult` returned should also contain a `http:` scheme.  As discussed in the [chapter on fuzzing with generators](GeneratorGrammarFuzzer.ipynb), equalities of strings such as `http:` across two symbols cannot be expressed in a context-free grammar.  We can, however, use a _generator function_ (also introduced in the [chapter on fuzzing with generators](GeneratorGrammarFuzzer.ipynb)) to automatically enforce such equalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example.  Invoking `geturl()` on a `urlparse()` result should return the URL as originally passed to `urlparse()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GeneratorGrammarFuzzer import GeneratorGrammarFuzzer, ProbabilisticGeneratorGrammarFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_ORACLE_GRAMMAR: Grammar = extend_grammar(URLPARSE_GRAMMAR,\n",
    "{\n",
    "     \"<call>\": [(\"assert urlparse('<url>').geturl() == '<url>'\",\n",
    "                 opts(post=lambda url_1, url_2: [None, url_1]))]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_oracle_fuzzer = GeneratorGrammarFuzzer(URLPARSE_ORACLE_GRAMMAR)\n",
    "test = urlparse_oracle_fuzzer.fuzz()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way, we can also check individual components of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_ORACLE_GRAMMAR: Grammar = extend_grammar(URLPARSE_GRAMMAR,\n",
    "{\n",
    "     \"<call>\": [(\"result = urlparse('<scheme>://<host><path>?<params>')\\n\"\n",
    "                 # + \"print(result)\\n\"\n",
    "                 + \"assert result.scheme == '<scheme>'\\n\"\n",
    "                 + \"assert result.netloc == '<host>'\\n\"\n",
    "                 + \"assert result.path == '<path>'\\n\"\n",
    "                 + \"assert result.query == '<params>'\",\n",
    "                 opts(post=lambda scheme_1, authority_1, path_1, params_1,\n",
    "                      scheme_2, authority_2, path_2, params_2:\n",
    "                      [None, None, None, None,\n",
    "                       scheme_1, authority_1, path_1, params_1]))]\n",
    "})\n",
    "\n",
    "# Get rid of unused symbols\n",
    "del URLPARSE_ORACLE_GRAMMAR[\"<url>\"]\n",
    "del URLPARSE_ORACLE_GRAMMAR[\"<query>\"]\n",
    "del URLPARSE_ORACLE_GRAMMAR[\"<authority>\"]\n",
    "del URLPARSE_ORACLE_GRAMMAR[\"<userinfo>\"]\n",
    "del URLPARSE_ORACLE_GRAMMAR[\"<port>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_oracle_fuzzer = GeneratorGrammarFuzzer(URLPARSE_ORACLE_GRAMMAR)\n",
    "test = urlparse_oracle_fuzzer.fuzz()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of generator functions may feel a bit cumbersome.  Indeed, if we uniquely stick to Python, we could also create a _unit test_ that directly invokes the fuzzer to generate individual parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzed_url_element(symbol):\n",
    "    return GrammarFuzzer(URLPARSE_GRAMMAR, start_symbol=symbol).fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme = fuzzed_url_element(\"<scheme>\")\n",
    "authority = fuzzed_url_element(\"<authority>\")\n",
    "path = fuzzed_url_element(\"<path>\")\n",
    "query = fuzzed_url_element(\"<params>\")\n",
    "url = \"%s://%s%s?%s\" % (scheme, authority, path, query)\n",
    "result = urlparse(url)\n",
    "# print(result)\n",
    "assert result.geturl() == url\n",
    "assert result.scheme == scheme\n",
    "assert result.path == path\n",
    "assert result.query == query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using such a unit test makes it easier to express oracles.  However, we lose the ability to systematically cover individual URL elements and alternatives as with [`GrammarCoverageFuzzer`](GrammarCoverageFuzzer.ipynb) as well as the ability to guide generation towards specific elements as with [`ProbabilisticGrammarFuzzer`](ProbabilisticGrammarFuzzer.ipynb).  Furthermore, a grammar allows us to generate tests for arbitrary programming languages and APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Synthesizing Data\n",
    "\n",
    "For `urlparse()`, we have used a very specific grammar for creating a very specific argument.  Many functions take basic data types as (some) arguments, though; we therefore define grammars that generate precisely those arguments.  Even better, we can define functions that _generate_ grammars tailored towards our specific needs, returning values in a particular range, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integers\n",
    "\n",
    "We introduce a simple grammar to produce integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import convert_ebnf_grammar, crange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProbabilisticGrammarFuzzer import ProbabilisticGrammarFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INT_EBNF_GRAMMAR: Grammar = {\n",
    "    \"<start>\": [\"<int>\"],\n",
    "    \"<int>\": [\"<_int>\"],\n",
    "    \"<_int>\": [\"(-)?<leaddigit><digit>*\", \"0\"],\n",
    "    \"<leaddigit>\": crange('1', '9'),\n",
    "    \"<digit>\": crange('0', '9')\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(INT_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INT_GRAMMAR = convert_ebnf_grammar(INT_EBNF_GRAMMAR)\n",
    "INT_GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_fuzzer = GrammarFuzzer(INT_GRAMMAR)\n",
    "print([int_fuzzer.fuzz() for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need integers in a specific range, we can add a generator function that does right that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import set_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_grammar_with_range(start, end):\n",
    "    int_grammar = extend_grammar(INT_GRAMMAR)\n",
    "    set_opts(int_grammar, \"<int>\", \"<_int>\",\n",
    "        opts(pre=lambda: random.randint(start, end)))\n",
    "    return int_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_fuzzer = GeneratorGrammarFuzzer(int_grammar_with_range(900, 1000))\n",
    "[int_fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floats\n",
    "\n",
    "The grammar for floating-point values closely resembles the integer grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_EBNF_GRAMMAR: Grammar = {\n",
    "    \"<start>\": [\"<float>\"],\n",
    "    \"<float>\": [(\"<_float>\", opts(prob=0.9)), \"inf\", \"NaN\"],\n",
    "    \"<_float>\": [\"<int>(.<digit>+)?<exp>?\"],\n",
    "    \"<exp>\": [\"e<int>\"]\n",
    "}\n",
    "FLOAT_EBNF_GRAMMAR.update(INT_EBNF_GRAMMAR)\n",
    "FLOAT_EBNF_GRAMMAR[\"<start>\"] = [\"<float>\"]\n",
    "\n",
    "assert is_valid_grammar(FLOAT_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_GRAMMAR = convert_ebnf_grammar(FLOAT_EBNF_GRAMMAR)\n",
    "FLOAT_GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_fuzzer = ProbabilisticGrammarFuzzer(FLOAT_GRAMMAR)\n",
    "print([float_fuzzer.fuzz() for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_grammar_with_range(start, end):\n",
    "    float_grammar = extend_grammar(FLOAT_GRAMMAR)\n",
    "    set_opts(float_grammar, \"<float>\", \"<_float>\", opts(\n",
    "        pre=lambda: start + random.random() * (end - start)))\n",
    "    return float_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_fuzzer = ProbabilisticGeneratorGrammarFuzzer(\n",
    "    float_grammar_with_range(900.0, 900.9))\n",
    "[float_fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we introduce a grammar for producing strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASCII_STRING_EBNF_GRAMMAR: Grammar = {\n",
    "    \"<start>\": [\"<ascii-string>\"],\n",
    "    \"<ascii-string>\": ['\"<ascii-chars>\"'],\n",
    "    \"<ascii-chars>\": [\n",
    "        (\"\", opts(prob=0.05)),\n",
    "        \"<ascii-chars><ascii-char>\"\n",
    "    ],\n",
    "    \"<ascii-char>\": crange(\" \", \"!\") + [r'\\\"'] + crange(\"#\", \"~\")\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(ASCII_STRING_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASCII_STRING_GRAMMAR = convert_ebnf_grammar(ASCII_STRING_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_fuzzer = ProbabilisticGrammarFuzzer(ASCII_STRING_GRAMMAR)\n",
    "print([string_fuzzer.fuzz() for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizing Composite Data\n",
    "\n",
    "From basic data, as discussed above, we can also produce _composite data_ in data structures such as sets or lists.  We illustrate such generation on lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_EBNF_GRAMMAR: Grammar = {\n",
    "    \"<start>\": [\"<list>\"],\n",
    "    \"<list>\": [\n",
    "        (\"[]\", opts(prob=0.05)),\n",
    "        \"[<list-objects>]\"\n",
    "    ],\n",
    "    \"<list-objects>\": [\n",
    "        (\"<list-object>\", opts(prob=0.2)),\n",
    "        \"<list-object>, <list-objects>\"\n",
    "    ],\n",
    "    \"<list-object>\": [\"0\"],\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(LIST_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_GRAMMAR = convert_ebnf_grammar(LIST_EBNF_GRAMMAR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our list generator takes a grammar that produces objects; it then instantiates a list grammar with the objects from these grammars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_grammar(object_grammar, list_object_symbol=None):\n",
    "    obj_list_grammar = extend_grammar(LIST_GRAMMAR)\n",
    "    if list_object_symbol is None:\n",
    "        # Default: Use the first expansion of <start> as list symbol\n",
    "        list_object_symbol = object_grammar[START_SYMBOL][0]\n",
    "\n",
    "    obj_list_grammar.update(object_grammar)\n",
    "    obj_list_grammar[START_SYMBOL] = [\"<list>\"]\n",
    "    obj_list_grammar[\"<list-object>\"] = [list_object_symbol]\n",
    "\n",
    "    assert is_valid_grammar(obj_list_grammar)\n",
    "\n",
    "    return obj_list_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_list_fuzzer = ProbabilisticGrammarFuzzer(list_grammar(INT_GRAMMAR))\n",
    "[int_list_fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list_fuzzer = ProbabilisticGrammarFuzzer(\n",
    "    list_grammar(ASCII_STRING_GRAMMAR))\n",
    "[string_list_fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_list_fuzzer = ProbabilisticGeneratorGrammarFuzzer(list_grammar(\n",
    "    float_grammar_with_range(900.0, 900.9)))\n",
    "[float_list_fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators for dictionaries, sets, etc. can be defined in a similar fashion.  By plugging together grammar generators, we can produce data structures with arbitrary elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "This chapter provides *grammar constructors* that are useful for generating _function calls_.\n",
    "\n",
    "The grammars are [probabilistic](ProbabilisticGrammarFuzzer.ipynb) and make use of [generators](GeneratorGrammarFuzzer.ipynb), so use `ProbabilisticGeneratorGrammarFuzzer` as a producer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GeneratorGrammarFuzzer import ProbabilisticGeneratorGrammarFuzzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`INT_GRAMMAR`, `FLOAT_GRAMMAR`, `ASCII_STRING_GRAMMAR` produce integers, floats, and strings, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzer = ProbabilisticGeneratorGrammarFuzzer(INT_GRAMMAR)\n",
    "[fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzer = ProbabilisticGeneratorGrammarFuzzer(FLOAT_GRAMMAR)\n",
    "[fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzer = ProbabilisticGeneratorGrammarFuzzer(ASCII_STRING_GRAMMAR)\n",
    "[fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`int_grammar_with_range(start, end)` produces an integer grammar with values `N` such that `start <= N <= end`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_grammar = int_grammar_with_range(100, 200)\n",
    "fuzzer = ProbabilisticGeneratorGrammarFuzzer(int_grammar)\n",
    "[fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`float_grammar_with_range(start, end)` produces a floating-number grammar with values `N` such that `start <= N <= end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_grammar = float_grammar_with_range(100, 200)\n",
    "fuzzer = ProbabilisticGeneratorGrammarFuzzer(float_grammar)\n",
    "[fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All such values can be immediately used for testing function calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzer = ProbabilisticGeneratorGrammarFuzzer(int_grammar)\n",
    "call = \"sqrt(\" + fuzzer.fuzz() + \")\"\n",
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These grammars can also be composed to form more complex grammars. `list_grammar(object_grammar)` returns a grammar that produces lists of objects as defined by `object_grammar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_list_grammar = list_grammar(int_grammar)\n",
    "fuzzer = ProbabilisticGeneratorGrammarFuzzer(int_list_grammar)\n",
    "[fuzzer.fuzz() for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_list = eval(fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(some_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar vein, we can construct arbitrary further data types for testing individual functions programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* To fuzz individual functions, one can easily set up grammars that produce function calls.\n",
    "* Fuzzing at the API level can be much faster than fuzzing at the system level, but brings the risk of false alarms by violating implicit preconditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "This chapter was all about manually writing test and controlling which data gets generated.  [In the next chapter](Carver.ipynb), we will introduce a much higher level of automation:\n",
    "\n",
    "* _Carving_ automatically records function calls and arguments from program executions.\n",
    "* We can turn these into _grammars_, allowing to test these functions with various combinations of recorded values.\n",
    "\n",
    "With these techniques, we automatically obtain grammars that already invoke functions in application contexts, making our work of specifying them much easier. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The idea of using generator functions to generate input structures was first explored in QuickCheck \\cite{Claessen2000}.   A very nice implementation for Python is the [hypothesis package](https://hypothesis.readthedocs.io/en/latest/) which allows writing and combining data structure generators for testing APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "The exercises for this chapter combine the above techniques with fuzzing techniques introduced earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1: Deep Arguments\n",
    "\n",
    "In the example generating oracles for `urlparse()`, important elements such as `authority` or `port` are not checked.  Enrich `URLPARSE_ORACLE_GRAMMAR` with post-expansion functions that store the generated elements in a symbol table, such that they can be accessed when generating the assertions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** Left to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 2: Covering Argument Combinations\n",
    "\n",
    "In the chapter on [configuration testing](ConfigurationFuzzer.ipynb), we also discussed _combinatorial testing_ – that is, systematic coverage of _sets_ of configuration elements.  Implement a scheme that by changing the grammar, allows all _pairs_ of argument values to be covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** Left to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 3: Mutating Arguments\n",
    "\n",
    "To widen the range of arguments to be used during testing, apply the _mutation schemes_ introduced in [mutation fuzzing](MutationFuzzer.ipynb) – for instance, flip individual bytes or delete characters from strings.  Apply this either during grammar inference or as a separate step when invoking functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** Left to the reader."
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
