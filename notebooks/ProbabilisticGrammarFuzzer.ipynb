{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "# Probabilistic Grammar Fuzzing\n",
    "\n",
    "Let us give grammars even more power by assigning _probabilities_ to individual expansions.  This allows us to control how many of each element should be produced, and thus allows us to _target_ our generated tests towards specific functionality.  We also show how to learn such probabilities from given sample inputs, and specifically direct our tests towards input features that are uncommon in these samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* Our implementation hooks into the grammar-based fuzzer introduced in [\"Efficient Grammar Fuzzing\"](GrammarFuzzer.ipynb)\n",
    "* For learning probabilities from samples, we make use of [parsers](Parser.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Law of Leading Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all our examples so far, you may have noted that inputs generated by a program differ quite a bit from \"natural\" inputs as they occur in real life.  This is true even for innocuous elements such as numbers – yes, the numbers we have generated so far actually _differ_ from numbers in the real world.  This is because in real-life sets of numerical data, the _leading significant digit_ is likely to be small: Actually, on average, the leading digit `1` occurs more than _six times_ as often as the leading digit `8` or `9`.  It has been shown that this result applies to a wide variety of data sets, including electricity bills, street addresses, stock prices, house prices, population numbers, death rates, lengths of rivers, physical and mathematical constants (Wikipedia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This law, first observed by Newcomb \\cite{Newcomb1881), was formalized by Benford in \\cite{Benford1938).  Let us take a look at the conditions that determine the first digit of a number.  We can easily compute the first digit by converting the number into a string and take the first character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_digit_via_string(x):\n",
    "    return ord(repr(x)[0]) - ord('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_digit_via_string(2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this mathematically, though, we have to take the fractional part of their logarithm, or formally\n",
    "\n",
    "$$\n",
    "d = 10^{\\{\\log_{10}(x)\\}}\n",
    "$$\n",
    "\n",
    "where $\\{x\\}$ is the fractional part of $x$ (i.e. $\\{1.234\\} = 0.234$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_digit_via_log(x):\n",
    "    frac, whole = math.modf(math.log10(x))\n",
    "    return int(10 ** frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_digit_via_log(2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most sets of \"naturally\" occurring numbers should not have any bias in the fractional parts of their logarithms, and hence, the fractional part $\\{\\log_{10}(x)\\}$ is typically uniformly distributed.  However, the fractional parts for the individual digits are _not_ evenly distributed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a number to start with a digit $d$, the condition $d < 10^{\\{\\log_{10}(x)\\}} < d + 1$ must hold.  To start with the digit 1, the fractional part $\\{\\log_{10}(x)\\}$ must thus be in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(math.log10(1), math.log10(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with the digit 2, though, it must be in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(math.log10(2), math.log10(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is much smaller.  Formally, the probability $P(d)$ for a leading digit $d$ (again, assuming uniformly distributed fractional parts) is known as Benford's law:\n",
    "$$\n",
    "P(d) = \\log_{10}(d + 1) - \\log_{10}(d)\n",
    "$$\n",
    "which gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_leading_digit(d):\n",
    "    return math.log10(d + 1) - math.log10(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute these probabilities for all digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_probs = [prob_leading_digit(d) for d in range(1, 10)]\n",
    "[(d, \"%.2f\" % digit_probs[d - 1]) for d in range(1, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(1, 10)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(digit_probs, labels=labels, shadow=True, autopct='%1.1f%%', \n",
    "        counterclock=False, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a leading 1 is indeed six times a probable than a leading 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benford's law has a number of applications.  Most notably, it can be used to detect \"non-natural\" numbers, i.e. numbers that apparently were created randomly rather than coming from a \"natural\" source.  if you write a scientific paper and fake data by putting in random numbers (for instance, [using our grammar fuzzer](GrammarFuzzer.ipynb) on integers), you will likely violate Benford's law, and this can indeed be spotted.  On the other hand, how would we proceed if we _wanted_ to create numbers that adhere to Benson's law?  To this end, we need to be able to _encode_ probabilities such as the above in our grammar, such that we can ensure that a leading digit is indeed a `1` in 30% of all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Probabilities\n",
    "\n",
    "The goal of this chapter is to assign _probabilities_ to individual expansions in the grammar, such that we can express that some expansion alternatives should be favored over others.  This is not only useful to generate \"natural\"-looking numbers, but even more so to _direct_ test generation towards a specific goal.  If you recently have changed some code in your program, you would probably like to generate inputs that exercise precisely this code.  By raising the probabilities on the input elements associated with the changed code, you will get more tests that exercise the changed code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our concept for expressing probabilities is to _annotate_ individual expansions with attributes such as probabilities.  To this end, we allow that an expansion cannot only be a string, but also a _pair_ of a string and a set of attributes, as in\n",
    "\n",
    "```python\n",
    "    \"<expr>\":\n",
    "        [(\"<term> + <expr>\", opts(prob=0.1)),\n",
    "         (\"<term> - <expr>\", opts(prob=0.2)),\n",
    "         \"<term>\"]\n",
    "```\n",
    "\n",
    "Here, the `opts()` function would allow us to express probabilities for choosing the individual expansions.  The addition would have a probability of 10%, the subtraction of 20%.  The remaining probability (in this case 70%) is equally distributed over the non-attributed expansions (in this case the single last one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `opts()` helper function returns a mapping of its arguments to values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opts(**kwargs):\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts(prob=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use pairs with `opts()` to assign probabilities to our expression grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "code_folding": [],
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer, all_terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "code_folding": [],
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from Grammars import is_valid_grammar, EXPR_GRAMMAR, START_SYMBOL, crange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "PROBABILISTIC_EXPR_GRAMMAR = {\n",
    "    \"<start>\":\n",
    "        [\"<expr>\"],\n",
    "\n",
    "    \"<expr>\":\n",
    "        [(\"<term> + <expr>\", opts(prob=0.1)),\n",
    "         (\"<term> - <expr>\", opts(prob=0.2)),\n",
    "         \"<term>\"],\n",
    "\n",
    "    \"<term>\":\n",
    "        [(\"<factor> * <term>\", opts(prob=0.1)),\n",
    "         (\"<factor> / <term>\", opts(prob=0.1)),\n",
    "         \"<factor>\"\n",
    "         ],\n",
    "\n",
    "    \"<factor>\":\n",
    "        [\"+<factor>\", \"-<factor>\", \"(<expr>)\",\n",
    "            \"<leadinteger>\", \"<leadinteger>.<integer>\"],\n",
    "\n",
    "    \"<leadinteger>\":\n",
    "        [\"<leaddigit><integer>\", \"<leaddigit>\"],\n",
    "\n",
    "    # Benford's law: frequency distribution of leading digits\n",
    "    \"<leaddigit>\":\n",
    "        [(\"1\", opts(prob=0.301)),\n",
    "         (\"2\", opts(prob=0.176)),\n",
    "         (\"3\", opts(prob=0.125)),\n",
    "         (\"4\", opts(prob=0.097)),\n",
    "         (\"5\", opts(prob=0.079)),\n",
    "         (\"6\", opts(prob=0.067)),\n",
    "         (\"7\", opts(prob=0.058)),\n",
    "         (\"8\", opts(prob=0.051)),\n",
    "         (\"9\", opts(prob=0.046)),\n",
    "         ],\n",
    "\n",
    "    # Remaining digits are equally distributed\n",
    "    \"<integer>\":\n",
    "        [\"<digit><integer>\", \"<digit>\"],\n",
    "\n",
    "    \"<digit>\":\n",
    "        [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "assert is_valid_grammar(PROBABILISTIC_EXPR_GRAMMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the grammar expansions are represented internally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBABILISTIC_EXPR_GRAMMAR[\"<leaddigit>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we typically access the expansion string and the associated probability via designated helper functions, `exp_string()` and `exp_prob()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_string(expansion):\n",
    "    \"\"\"Return the string to be expanded\"\"\"\n",
    "    if isinstance(expansion, str):\n",
    "        return expansion\n",
    "    return expansion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaddigit_expansion = PROBABILISTIC_EXPR_GRAMMAR[\"<leaddigit>\"][0]\n",
    "leaddigit_expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_string(leaddigit_expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_opts(expansion):\n",
    "    \"\"\"Return the options of an expansion\"\"\"\n",
    "    if isinstance(expansion, str):\n",
    "        return None\n",
    "    return expansion[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_opts(leaddigit_expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_prob(expansion):\n",
    "    \"\"\"Return the specified probability, or None if unspecified\"\"\"\n",
    "    if isinstance(expansion, str):\n",
    "        return None\n",
    "    return exp_opts(expansion)['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prob(leaddigit_expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, our existing fuzzers have been set up to work well with grammars annotated this way.  They simply ignore all annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarCoverageFuzzer import GrammarCoverageFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(PROBABILISTIC_EXPR_GRAMMAR)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Computing Probabilities\n",
    "\n",
    "Let us define functions that access probabilities for given expansions.  While doing so, they also check for inconsistencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributing Probabilities\n",
    "\n",
    "Here is how we distribute probabilities for expansions without specified probabilities. Given an expansion rule\n",
    "\n",
    "$$S ::= a_1\\:|\\: a_2 \\:|\\: \\dots \\:|\\: a_n \\:|\\: u_1 \\:|\\: u_2 \\:|\\: \\dots u_m$$\n",
    "\n",
    "with $n \\ge 0$ alternatives $a_i$ for which the probability $p(a_i)$ is _specified_ and\n",
    "$m \\ge 0$ alternatives $u_j$ for which the probability $p(u_j)$ is _unspecified_, \n",
    "the \"remaining\" probability is distributed equally over all $u_j$; in other words,\n",
    "\n",
    "$$p(u_j) = \\frac{1 - \\sum_{i = 0}^{n}p(a_i)}{m}$$\n",
    "\n",
    "If no probabilities are specified ($n = 0$), then all expansions have the same probability.\n",
    "\n",
    "The overall sum of probabilities must be 1:\n",
    "\n",
    "$$\\sum_{i = 0}^{n} p(a_i) + \\sum_{j = 0}^{m} p(u_i) = 1$$\n",
    "\n",
    "We check these properties while distributing probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `exp_probabilities()` returns a mapping of all expansions in a rule to their respective probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_probabilities(expansions, nonterminal=\"<symbol>\"):\n",
    "    probabilities = [exp_prob(expansion) for expansion in expansions]\n",
    "    prob_dist = prob_distribution(probabilities, nonterminal)\n",
    "    \n",
    "    prob_mapping = {}\n",
    "    for i in range(len(expansions)):\n",
    "        expansion = exp_string(expansions[i])\n",
    "        prob_mapping[expansion] = prob_dist[i]\n",
    "    \n",
    "    return prob_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gist of `exp_probabilities()` is handled in `prob_distribution()`, which does the actual checking and computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_distribution(probabilities, nonterminal=\"<symbol>\"):\n",
    "    epsilon = 0.00001\n",
    "\n",
    "    number_of_unspecified_probabilities = probabilities.count(None)\n",
    "    if number_of_unspecified_probabilities == 0:\n",
    "        assert abs(sum(probabilities) - 1.0) < epsilon, \\\n",
    "            nonterminal + \": sum of probabilities must be 1.0\"\n",
    "        return probabilities\n",
    "\n",
    "    sum_of_specified_probabilities = 0.0\n",
    "    for p in probabilities:\n",
    "        if p is not None:\n",
    "            sum_of_specified_probabilities += p\n",
    "    assert 0 <= sum_of_specified_probabilities <= 1.0, \\\n",
    "        nonterminal + \": sum of specified probabilities must be between 0.0 and 1.0\"\n",
    "\n",
    "    default_probability = ((1.0 - sum_of_specified_probabilities) / \n",
    "         number_of_unspecified_probabilities)\n",
    "    all_probabilities = []\n",
    "    for p in probabilities:\n",
    "        if p is None:\n",
    "            p = default_probability\n",
    "        all_probabilities.append(p)\n",
    "\n",
    "    assert abs(sum(all_probabilities) - 1.0) < epsilon\n",
    "    return all_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the mapping `exp_probabilities()` returns for the annotated `<leaddigit>` element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_probabilities(PROBABILISTIC_EXPR_GRAMMAR[\"<leaddigit>\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no expansion is annotated, all expansions have the same likelihood of being selected, as in our previous grammar fuzzers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_probabilities(PROBABILISTIC_EXPR_GRAMMAR[\"<digit>\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how `exp_probabilities()` distributes any remaining probability across non-annotated expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_probabilities(PROBABILISTIC_EXPR_GRAMMAR[\"<expr>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the checking capabilities of `exp_probabilities()` to check a probabilistic grammar for consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_probabilistic_grammar(grammar, start_symbol=START_SYMBOL):\n",
    "    if not is_valid_grammar(grammar, start_symbol):\n",
    "        return False\n",
    "   \n",
    "    for nonterminal in grammar:\n",
    "        expansions = grammar[nonterminal]\n",
    "        prob_dist = exp_probabilities(expansions, nonterminal)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_probabilistic_grammar(PROBABILISTIC_EXPR_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_probabilistic_grammar(EXPR_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpectError import ExpectError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError():\n",
    "    assert is_valid_probabilistic_grammar({\"<start>\": [(\"1\", opts(prob=0.5))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError():\n",
    "    assert is_valid_probabilistic_grammar({\"<start>\": [(\"1\", opts(prob=1.5)), \"2\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding by Probability\n",
    "\n",
    "Now that we have seen how to specify probabilities for a grammar, we can actually implement probabilistic expansion.  In our `ProbabilisticGrammarFuzzer`, it suffices to overload one method, namely `choose_node_expansion()`.  For each of the children we can choose from (typically all expansions of a symbol), we determine their probability (using `exp_probabilities()` defined above), and make a weighted choice using `random.choices()` with a `weight` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticGrammarFuzzer(GrammarFuzzer):\n",
    "    def choose_node_expansion(self, node, possible_children):\n",
    "        (symbol, tree) = node\n",
    "        expansions = self.grammar[symbol]\n",
    "        probabilities = exp_probabilities(expansions)\n",
    "\n",
    "        weights = []\n",
    "        for child in possible_children:\n",
    "            expansion = all_terminals((node, child))\n",
    "            child_weight = probabilities[expansion]\n",
    "            if self.log:\n",
    "                print(repr(expansion), \"p =\", child_weight)\n",
    "            weights.append(child_weight)\n",
    "            \n",
    "        if sum(weights) == 0:\n",
    "            # No alternative (probably expanding at minimum cost)\n",
    "            weights = None\n",
    "            \n",
    "        return random.choices(range(len(possible_children)), weights=weights)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our probabilistic grammar fuzzer works just like the non-probabilistic grammar fuzzer, except that it actually respects probability annotations.  Let us generate a couple of \"natural\" numbers that respect Benford's law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_fuzzer = ProbabilisticGrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leadinteger>\")\n",
    "print([natural_fuzzer.fuzz() for i in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, these numbers are pure random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_fuzzer = GrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leadinteger>\")\n",
    "print([integer_fuzzer.fuzz() for i in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the \"natural\" numbers really more \"natural\" than the random ones?  To show that `ProbabilisticGrammarFuzzer` indeed respects  the probabilistic annotations, let us create a specific fuzzer for the lead digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaddigit_fuzzer = ProbabilisticGrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leaddigit>\")\n",
    "leaddigit_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we generate thousands of lead digits, their distribution should again follow Benford's law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 10000\n",
    "\n",
    "count = {}\n",
    "for c in crange('0', '9'):\n",
    "    count[c] = 0\n",
    "\n",
    "for i in range(trials):\n",
    "    count[leaddigit_fuzzer.fuzz()] += 1\n",
    "\n",
    "print([(digit, count[digit] / trials) for digit in count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quod erat demonstrandum! The distribution is pretty much exactly as originally specified.  We now have a fuzzer where we can exercise control by specifying probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Fuzzing\n",
    "\n",
    "Assigning probabilities to individual expansions gives us great control over which inputs should be generated.  By choosing probabilities wisely, we can _direct_ fuzzing towards specific functions and features – for instance, towards functions that are particularly critical, prone to failures, or that have been recently changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the URL grammar from the [chapter on grammars](Grammars.ipynb).  Let us assume we have just made a change to our implementation of the secure FTP protocol.  By assigning a higher probability to the `ftps` scheme, we can generate more URLs that will specifically test this functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us define a helper function that sets a particular option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import URL_GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_opts(grammar, symbol, expansion, opts=None):\n",
    "    \"\"\"Set the options of the given expansion of grammar[symbol] to opts\"\"\"\n",
    "    expansions = grammar[symbol]\n",
    "    for i in range(len(expansions)):\n",
    "        exp = expansions[i]\n",
    "        if exp_string(exp) == expansion:\n",
    "            new_opts = exp_opts(exp)\n",
    "            if opts is None or new_opts is None:\n",
    "                new_opts = opts\n",
    "            else:\n",
    "                for key in opts:\n",
    "                    new_opts[key] = opts[key]\n",
    "            if new_opts is None:\n",
    "                grammar[symbol][i] = exp_string(exp)\n",
    "            else:\n",
    "                grammar[symbol][i] = (exp_string(exp), new_opts)\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a specialization just for probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_prob(grammar, symbol, expansion, prob):\n",
    "    \"\"\"Set the probability of the given expansion of grammar[symbol]\"\"\"\n",
    "    set_opts(grammar, symbol, expansion, opts(prob=prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use `set_prob()` to give the `ftps` expansion a probability of 80%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_url_grammar = copy.deepcopy(URL_GRAMMAR)\n",
    "set_prob(probabilistic_url_grammar, \"<scheme>\", \"ftps\", 0.8)\n",
    "assert is_valid_probabilistic_grammar(probabilistic_url_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_url_grammar[\"<scheme>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use this grammar for fuzzing, we will get plenty of `ftps:` prefixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_url_fuzzer = ProbabilisticGrammarFuzzer(probabilistic_url_grammar)\n",
    "for i in range(10):\n",
    "    print(prob_url_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar vein, we can direct URL generation towards specific hosts or ports; we can favor URLs with queries, fragments, or logins – or URLs without these.  All it takes is to set appropriate probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the probability of an expansion to zero, we can effectively disable specific expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prob(probabilistic_url_grammar, \"<scheme>\", \"ftps\", 0.0)\n",
    "assert is_valid_probabilistic_grammar(probabilistic_url_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_url_fuzzer = ProbabilisticGrammarFuzzer(probabilistic_url_grammar)\n",
    "for i in range(10):\n",
    "    print(prob_url_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even if we set the probability of an expansion to zero, we may still see the expansion taken. This can happen during the \"closing\" phase of [our grammar fuzzer](GrammarFuzzer.ipynb), when the expansion is closed at minimum cost.  At this stage, even expansions with \"zero\" probability will be taken if this is necessary for closing the expansion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate this feature using the `<expr>` rule from our expression grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import EXPR_GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_expr_grammar = copy.deepcopy(EXPR_GRAMMAR)\n",
    "probabilistic_expr_grammar[\"<expr>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set the probability of the `<term>` expansion to zero, the string should expand again and again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prob(probabilistic_expr_grammar, \"<expr>\", \"<term>\", 0.0)\n",
    "assert is_valid_probabilistic_grammar(probabilistic_expr_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, in the \"closing\" phase, subexpressions will eventually expand into `<term>`, as it is the only way to close the expansion.  Tracking `choose_node_expansion()` shows that is is invoked with only one possible expansion `<term>`, which has to be taken even though its specified probability is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_expr_fuzzer = ProbabilisticGrammarFuzzer(probabilistic_expr_grammar)\n",
    "prob_expr_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities in Context\n",
    "\n",
    "While specified probabilities give us a means to control which expansions are taken how often, this control by itself may not be enough.  As an example, consider the following grammar for IPv4 addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrange(start, end):\n",
    "    \"\"\"Return a list with string representations of numbers in the range [start, end)\"\"\"\n",
    "    return [repr(n) for n in range(start, end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_ADDRESS_GRAMMAR = {\n",
    "    \"<start>\": [\"<address>\"],\n",
    "    \"<address>\": [ \"<octet>.<octet>.<octet>.<octet>\" ],\n",
    "    \"<octet>\": decrange(0, 256)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_grammar(IP_ADDRESS_GRAMMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily use this grammar to create IP addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_fuzzer = ProbabilisticGrammarFuzzer(IP_ADDRESS_GRAMMAR)\n",
    "ip_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we want to assign a specific probability to one of the four octets, we are out of luck.  All we can do is to assign the same probability distribution for all four octets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_ip_address_grammar = copy.deepcopy(IP_ADDRESS_GRAMMAR)\n",
    "set_prob(probabilistic_ip_address_grammar, \"<octet>\", \"127\", 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_ip_fuzzer = ProbabilisticGrammarFuzzer(probabilistic_ip_address_grammar)\n",
    "probabilistic_ip_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to assign _different_ probabilities to each of the four octets, what do we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer lies in the concept of _context_, which we already have seen [while discussing coverage-driven fuzzers](GrammarCoverageFuzzer.ipynb).  As with coverage-driven fuzzing, the idea is to _duplicate_ the element whose probability we want to set dependent on its context.  In our case, this means to duplicate the `<octet>` element to four individual ones, each of which can then get an individual probability distribution.  We can do this programmatically, using the `duplicate_context()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarCoverageFuzzer import duplicate_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_ip_address_grammar = copy.deepcopy(IP_ADDRESS_GRAMMAR)\n",
    "duplicate_context(probabilistic_ip_address_grammar, \"<address>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_ip_address_grammar[\"<address>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original `<octet>` definition is now no longer required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del probabilistic_ip_address_grammar[\"<octet>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assign different probabilities to each of the `<octet>` symbols.  For instance, we can force specific expansions by setting their probability to 100%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prob(probabilistic_ip_address_grammar, \"<octet-1>\", \"127\", 1.0)\n",
    "set_prob(probabilistic_ip_address_grammar, \"<octet-2>\", \"0\", 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_probabilistic_grammar(probabilistic_ip_address_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining two octets `<octet-3>` and `<octet-4>` have no specific probabilities set.  During fuzzing, all their expansions (all octets) are thus still available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic_ip_fuzzer = ProbabilisticGrammarFuzzer(probabilistic_ip_address_grammar)\n",
    "[probabilistic_ip_fuzzer.fuzz() for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with coverage, we can duplicate grammar rules arbitrarily often to get more and more finer-grained control over probabilities.  However, this finer-grained control also comes at the cost of having to maintain these probabilities.  In the next section, we will therefore discuss means to assign and tune such probabilities automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Probabilities from Samples\n",
    "\n",
    "Probabilities need not be set manually all the time.  They can also be _learned_ from other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import EarleyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import display_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = EarleyParser(IP_ADDRESS_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = parser.parse(\"127.0.0.1\")[0]\n",
    "display_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\todo{FIXME: \"127\" should be one string}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Count individual expansions over a sample as weights.\n",
    "2. Assign these as probabilities to the grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Tuning Probabilities\n",
    "\n",
    "1. First, generate a set of inputs.\n",
    "2. Then, measure coverage.\n",
    "3. Pick the slice of inputs that satisfies a particular goal (say, coverage).\n",
    "4. Learn probabilities from these.\n",
    "5. Repeat :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Coverage import Coverage, cgi_decode\n",
    "from Grammars import CGI_GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgi_fuzzer = GrammarFuzzer(CGI_GRAMMAR)\n",
    "\n",
    "trials = 100\n",
    "coverage = {}\n",
    "\n",
    "for i in range(trials):\n",
    "    cgi_input = cgi_fuzzer.fuzz()\n",
    "    with Coverage() as cov:\n",
    "        cgi_decode(cgi_input)\n",
    "    coverage[cgi_input] = cov.coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_slice = [cgi_input for cgi_input in coverage if ('cgi_decode', 25) in coverage[cgi_input]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coverage_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coverage_slice) / trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this sample for setting probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* _Lesson one_\n",
    "* _Lesson two_\n",
    "* _Lesson three_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Our exposition of Benford's law follows [this article](https://brilliant.org/wiki/benfords-law/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Close the chapter with a few exercises such that people have things to do.  In Jupyter Notebook, use the `exercise2` nbextension to add solutions that can be interactively viewed or hidden:\n",
    "\n",
    "* Mark the _last_ cell of the exercise (this should be a _text_ cell) as well as _all_ cells of the solution.  (Use the `rubberband` nbextension and use Shift+Drag to mark multiple cells.)\n",
    "* Click on the `solution` button at the top.\n",
    "\n",
    "(Alternatively, just copy the exercise and solution cells below with their metadata.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a class `ProbabilisticGrammarCoverageFuzzer` that extends `GrammarCoverageFuzzer` with probabilistic capabilities.  The idea is to first cover all uncovered expansions (like `GrammarCoverageFuzzer`) and once all expansions are covered, to proceed by probabilities (like `ProbabilisticGrammarFuzzer`).  To this end, define new instances of the `choose_covered_node_expansion()` and `choose_uncovered_node_expansion()` methods that choose an expansion based on the given weights.  If you are an advanced programmer, realize the class via _multiple inheritance_ from `GrammarCoverageFuzzer` and `ProbabilisticGrammarFuzzer` to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution**.  With multiple inheritance, this is fairly easy; we just need to point the three methods to the right places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class ProbabilisticGrammarCoverageFuzzer(GrammarCoverageFuzzer, ProbabilisticGrammarFuzzer):\n",
    "    # Choose uncovered expansions first\n",
    "    def choose_node_expansion(self, node, possible_children):\n",
    "        return GrammarCoverageFuzzer.choose_node_expansion(self, node, possible_children)\n",
    "\n",
    "    # Among uncovered expansions, pick by (relative) probability\n",
    "    def choose_uncovered_node_expansion(self, node, possible_children):\n",
    "        return ProbabilisticGrammarFuzzer.choose_node_expansion(self, node, possible_children)\n",
    "    \n",
    "    # For covered nodes, pick by probability, too\n",
    "    def choose_covered_node_expansion(self, node, possible_children):\n",
    "        return ProbabilisticGrammarFuzzer.choose_node_expansion(self, node, possible_children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "In the first nine invocations, our fuzzer covers one digit after another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "cov_leaddigit_fuzzer = ProbabilisticGrammarCoverageFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leaddigit>\")\n",
    "print([cov_leaddigit_fuzzer.fuzz() for i in range(9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "After these, we again proceed by probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "trials = 10000\n",
    "\n",
    "count = {}\n",
    "for c in crange('0', '9'):\n",
    "    count[c] = 0\n",
    "\n",
    "for i in range(trials):\n",
    "    count[cov_leaddigit_fuzzer.fuzz()] += 1\n",
    "\n",
    "print([(digit, count[digit] / trials) for digit in count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Test: \\cite{Holler2012}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "_Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
