{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Probabilistic Grammar Fuzzing\n",
    "\n",
    "Let us give grammars even more power by assigning _probabilities_ to individual expansions.  This allows us to control how many of each element should be produced, and thus allows us to _target_ our generated tests towards specific functionality.  We also show how to learn such probabilities from given sample inputs, and specifically direct our tests towards input features that are uncommon in these samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* Our implementation hooks into the grammar-based fuzzer introduced in [\"Efficient Grammar Fuzzing\"](GrammarFuzzer.ipynb)\n",
    "* For learning probabilities from samples, we make use of [parsers](Parser.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Law of Leading Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all our examples so far, you may have noted that inputs generated by a program differ quite a bit from \"natural\" inputs as they occur in real life.  This is true even for innocuous elements such as numbers – yes, the numbers we have generated so far actually _differ_ from numbers in the real world.  This is because in real-life sets of numerical data, the _leading significant digit_ is likely to be small: Actually, on average, the leading digit `1` occurs more than _six times_ as often as the leading digit `8` or `9`.  It has been shown that this result applies to a wide variety of data sets, including electricity bills, street addresses, stock prices, house prices, population numbers, death rates, lengths of rivers, physical and mathematical constants (Wikipedia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This law, first observed by Newcomb \\cite{Newcomb1881), was formalized by Benford in \\cite{Benford1938).  Let us take a look at the conditions that determine the first digit of a number.  We can easily compute the first digit by converting the number into a string and take the first character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_digit_via_string(x):\n",
    "    return ord(repr(x)[0]) - ord('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_digit_via_string(2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this mathematically, though, we have to take the fractional part of their logarithm, or formally\n",
    "\n",
    "$$\n",
    "d = 10^{\\{\\log_{10}(x)\\}}\n",
    "$$\n",
    "\n",
    "where $\\{x\\}$ is the fractional part of $x$ (i.e. $\\{1.234\\} = 0.234$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_digit_via_log(x):\n",
    "    frac, whole = math.modf(math.log10(x))\n",
    "    return int(10 ** frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_digit_via_log(2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most sets of \"naturally\" occurring numbers should not have any bias in the fractional parts of their logarithms, and hence, the fractional part $\\{\\log_{10}(x)\\}$ is typically uniformly distributed.  However, the fractional parts for the individual digits are _not_ evenly distributed.  \n",
    "\n",
    "For a number to start with a digit $d$, the condition $d < 10^{\\{\\log_{10}(x)\\}} < d + 1$ must hold.  To start with the digit 1, the fractional part $\\{\\log_{10}(x)\\}$ must thus be in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(math.log10(1), math.log10(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with the digit 2, though, it must be in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(math.log10(2), math.log10(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is much smaller.  Formally, the probability $P(d)$ for a leading digit $d$ (again, assuming uniformly distributed fractional parts) is known as Benford's law:\n",
    "$$\n",
    "P(d) = \\log_{10}(d + 1) - \\log_{10}(d)\n",
    "$$\n",
    "which gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_leading_digit(d):\n",
    "    return math.log10(d + 1) - math.log10(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(d, prob_leading_digit(d)) for d in range(1, 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and you can see that a leading 1 is indeed six times a probable than a leading 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benford's law has a number of applications.  Most notably, it can be used to detect \"non-natural\" numbers, i.e. numbers that apparently were created randomly rather than coming from a \"natural\" source.  if you write a scientific paper and fake data by putting in random numbers (for instance, [using our grammar fuzzer](GrammarFuzzer.ipynb) on integers), you will likely violate Benford's law, and this can indeed be spotted.  On the other hand, how would we proceed if we _wanted_ to create numbers that adhere to Benson's law?  To this end, we need to be able to _encode_ probabilities such as the above in our grammar, such that we can ensure that a leading digit is indeed a `1` in 30% of all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Probabilities\n",
    "\n",
    "The goal of this chapter is to assign _probabilities_ to individual expansions in the grammar, such that we can express that some expansion alternatives should be favored over others.  This is not only useful to generate \"natural\"-looking numbers, but even more so to _direct_ test generation towards a specific goal.  If you recently have changed some code in your program, you would probably like to generate inputs that exercise precisely this code.  By raising the probabilities on the input elements associated with the changed code, you will get more tests that exercise the changed code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our concept for expressing probabilities is to _annotate_ individual expansions with attributes such as probabilities.  To this end, we allow that an expansion cannot only be a string, but also a _pair_ of a string and a set of attributes, as in\n",
    "\n",
    "```python\n",
    "    \"<expr>\":\n",
    "        [(\"<term> + <expr>\", opts(prob=0.1)),\n",
    "         (\"<term> - <expr>\", opts(prob=0.2)),\n",
    "         \"<term>\"]\n",
    "```\n",
    "\n",
    "Here, the `opts()` function would allow us to express probabilities for choosing the individual expansions.  The addition would have a probability of 10%, the subtraction of 20%.  The remaining probability (in this case 70%) is equally distributed over the non-attributed expansions (in this case the single last one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `opts()` helper function returns a mapping of its arguments to values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opts(**kwargs):\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts(prob=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use pairs with `opts()` to assign probabilities to our expression grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "code_folding": [],
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer, all_terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "code_folding": [],
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from Grammars import is_valid_grammar, EXPR_GRAMMAR, START_SYMBOL, crange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "PROBABILISTIC_EXPR_GRAMMAR = {\n",
    "    \"<start>\":\n",
    "        [\"<expr>\"],\n",
    "\n",
    "    \"<expr>\":\n",
    "        [(\"<term> + <expr>\", opts(prob=0.1)),\n",
    "         (\"<term> - <expr>\", opts(prob=0.2)),\n",
    "         \"<term>\"],\n",
    "\n",
    "    \"<term>\":\n",
    "        [(\"<factor> * <term>\", opts(prob=0.1)),\n",
    "         (\"<factor> / <term>\", opts(prob=0.1)),\n",
    "         \"<factor>\"\n",
    "         ],\n",
    "\n",
    "    \"<factor>\":\n",
    "        [\"+<factor>\", \"-<factor>\", \"(<expr>)\",\n",
    "            \"<leadinteger>\", \"<leadinteger>.<integer>\"],\n",
    "\n",
    "    \"<leadinteger>\":\n",
    "        [\"<leaddigit><integer>\", \"<leaddigit>\"],\n",
    "\n",
    "    # Benford's law: frequency distribution of leading digits\n",
    "    \"<leaddigit>\":\n",
    "        [(\"1\", opts(prob=0.301)),\n",
    "         (\"2\", opts(prob=0.176)),\n",
    "         (\"3\", opts(prob=0.125)),\n",
    "         (\"4\", opts(prob=0.097)),\n",
    "         (\"5\", opts(prob=0.079)),\n",
    "         (\"6\", opts(prob=0.067)),\n",
    "         (\"7\", opts(prob=0.058)),\n",
    "         (\"8\", opts(prob=0.051)),\n",
    "         (\"9\", opts(prob=0.046)),\n",
    "         ],\n",
    "\n",
    "    # Remaining digits are equally distributed\n",
    "    \"<integer>\":\n",
    "        [\"<digit><integer>\", \"<digit>\"],\n",
    "\n",
    "    \"<digit>\":\n",
    "        [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "assert is_valid_grammar(PROBABILISTIC_EXPR_GRAMMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the grammar expansions are represented internally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBABILISTIC_EXPR_GRAMMAR[\"<leaddigit>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we typically access the expansion string and the associated probability via designated helper functions, `exp_string()` and `exp_prob()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_string(expansion):\n",
    "    \"\"\"Return the string to be expanded\"\"\"\n",
    "    if isinstance(expansion, str):\n",
    "        return expansion\n",
    "    return expansion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_string(PROBABILISTIC_EXPR_GRAMMAR[\"<leaddigit>\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_prob(expansion):\n",
    "    \"\"\"Return the specified probability, or None if unspecified\"\"\"\n",
    "    if isinstance(expansion, str):\n",
    "        return None\n",
    "    return expansion[1]['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prob(PROBABILISTIC_EXPR_GRAMMAR[\"<leaddigit>\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, our existing fuzzers have been set up to work well with grammars annotated this way.  They simply ignore all annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarCoverageFuzzer import GrammarCoverageFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(PROBABILISTIC_EXPR_GRAMMAR)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Probabilities\n",
    "\n",
    "To access probabilities, the function `prob_distribution()` returns a mapping of all expansions in a rule to their respective probabilities, also including those expansions without specified probabilities.  While doing so, it also checks for inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_probabilities(expansions, nonterminal=\"<symbol>\"):\n",
    "    probabilities = [exp_prob(expansion) for expansion in expansions]\n",
    "    prob_dist = prob_distribution(probabilities, nonterminal)\n",
    "    \n",
    "    prob_mapping = {}\n",
    "    for i in range(len(expansions)):\n",
    "        expansion = exp_string(expansions[i])\n",
    "        prob_mapping[expansion] = prob_dist[i]\n",
    "    \n",
    "    return prob_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_distribution(probabilities, nonterminal=\"<symbol>\"):\n",
    "    epsilon = 0.00001\n",
    "\n",
    "    number_of_unspecified_probabilities = probabilities.count(None)\n",
    "    if number_of_unspecified_probabilities == 0:\n",
    "        assert abs(sum(probabilities) - 1.0) < epsilon, \\\n",
    "            nonterminal + \": sum of probabilities must be 1.0\"\n",
    "        return probabilities\n",
    "\n",
    "    sum_of_specified_probabilities = 0.0\n",
    "    for p in probabilities:\n",
    "        if p is not None:\n",
    "            sum_of_specified_probabilities += p\n",
    "    assert 0 <= sum_of_specified_probabilities <= 1.0, \\\n",
    "        nonterminal + \": sum of specified probabilities must be between 0.0 and 1.0\"\n",
    "\n",
    "    default_probability = ((1.0 - sum_of_specified_probabilities) / \n",
    "         number_of_unspecified_probabilities)\n",
    "    all_probabilities = []\n",
    "    for p in probabilities:\n",
    "        if p is None:\n",
    "            p = default_probability\n",
    "        all_probabilities.append(p)\n",
    "\n",
    "    assert abs(sum(all_probabilities) - 1.0) < epsilon\n",
    "    return all_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the mapping `exp_probabilities()` returns for the annotated `<leaddigit>` element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_probabilities(PROBABILISTIC_EXPR_GRAMMAR[\"<leaddigit>\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no expansion is annotated, all expansions have the same likelihood of being selected, as in our previous grammar fuzzers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_probabilities(PROBABILISTIC_EXPR_GRAMMAR[\"<digit>\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`exp_probabilities()` distributes any remaining percentage across non-annotated expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_probabilities(PROBABILISTIC_EXPR_GRAMMAR[\"<expr>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the checking capabilities of `exp_probabilities()` to check a probabilistic grammar for consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_probabilistic_grammar(grammar, start_symbol=START_SYMBOL):\n",
    "    if not is_valid_grammar(grammar, start_symbol):\n",
    "        return False\n",
    "   \n",
    "    for nonterminal in grammar:\n",
    "        expansions = grammar[nonterminal]\n",
    "        prob_dist = exp_probabilities(expansions, nonterminal)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_probabilistic_grammar(PROBABILISTIC_EXPR_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_probabilistic_grammar(EXPR_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpectError import ExpectError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError():\n",
    "    assert not is_valid_probabilistic_grammar({\"<start>\": [(\"1\", opts(prob=0.5))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError():\n",
    "    assert not is_valid_probabilistic_grammar({\"<start>\": [(\"1\", opts(prob=1.5)), \"2\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting by Probability\n",
    "\n",
    "Now that we have seen how to specify probabilities for a grammar, we can actually implement probabilistic selection.  In our `ProbabilisticGrammarFuzzer`, it suffices to overload one method, namely `choose_node_expansion()`.  For each of the children we can choose from (typically all expansions of a symbol), we determine their probability (using `exp_probabilities()`), and make a weighted choice using `random.choices()` with a `weight` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticGrammarFuzzer(GrammarFuzzer):\n",
    "    def choose_node_expansion(self, node, possible_children):\n",
    "        (symbol, tree) = node\n",
    "        expansions = self.grammar[symbol]\n",
    "        probabilities = exp_probabilities(expansions)\n",
    "\n",
    "        weights = []\n",
    "        for child in possible_children:\n",
    "            child_weight = probabilities[all_terminals((node, child))]\n",
    "            weights.append(child_weight)\n",
    "            \n",
    "        return random.choices(range(len(possible_children)), weights=weights)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our probabilistic grammar fuzzer works just like the non-probabilistic grammar fuzzer, except that it actually respects probability annotations.  Let us generate a couple of \"natural\" numbers that respect Benford's law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_fuzzer = ProbabilisticGrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leadinteger>\")\n",
    "print([natural_fuzzer.fuzz() for i in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, these numbers are pure random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_fuzzer = GrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leadinteger>\")\n",
    "print([integer_fuzzer.fuzz() for i in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the \"natural\" numbers really more \"natural\" than the random ones?  To show that `ProbabilisticGrammarFuzzer` indeed respects  the probabilistic annotations, let us create a specific fuzzer for the lead digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaddigit_fuzzer = ProbabilisticGrammarFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leaddigit>\")\n",
    "leaddigit_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we generate thousands of lead digits, their distribution should again follow Benford's law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 10000\n",
    "\n",
    "count = {}\n",
    "for c in crange('0', '9'):\n",
    "    count[c] = 0\n",
    "\n",
    "for i in range(trials):\n",
    "    count[leaddigit_fuzzer.fuzz()] += 1\n",
    "\n",
    "print([(digit, count[digit] / trials) for digit in count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quod erat demonstrandum! The distribution is pretty much exactly as originally specified.  We now have a fuzzer where we can exercise control by specifying probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Fuzzing\n",
    "\n",
    "By choosing probabilities wisely, we can direct fuzzing towards specific functions.  (Say, `urlparse()`),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Probabilities from Samples\n",
    "\n",
    "In all our examples so far, you may have noted that inputs generated by a program differ quite a bit from \"natural\" inputs as they occur in real life.  This can be seen as a feature of test generation: The more generated inputs differ from natural inputs, the higher their chance of triggering new bugs – assuming they get accepted by the program under test, of course.  On the other hand, sometimes we also may want to generate inputs that share properties with \"natural\" inputs – for instance, if it comes to convincing developers that their code crashes not only for a pathological case, but also for inputs that may occur at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* _Lesson one_\n",
    "* _Lesson two_\n",
    "* _Lesson three_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Our exposition of Benford's law follows [this article](https://brilliant.org/wiki/benfords-law/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Close the chapter with a few exercises such that people have things to do.  In Jupyter Notebook, use the `exercise2` nbextension to add solutions that can be interactively viewed or hidden:\n",
    "\n",
    "* Mark the _last_ cell of the exercise (this should be a _text_ cell) as well as _all_ cells of the solution.  (Use the `rubberband` nbextension and use Shift+Drag to mark multiple cells.)\n",
    "* Click on the `solution` button at the top.\n",
    "\n",
    "(Alternatively, just copy the exercise and solution cells below with their metadata.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a class `ProbabilisticGrammarCoverageFuzzer` that extends `GrammarCoverageFuzzer` with probabilistic capabilities.  The idea is to first cover all uncovered expansions (like `GrammarCoverageFuzzer`) and once all expansions are covered, to proceed by probabilities (like `ProbabilisticGrammarFuzzer`).  To this end, define new instances of the `choose_covered_node_expansion()` and `choose_uncovered_node_expansion()` methods that choose an expansion based on the given weights.  If you are an advanced programmer, realize the class via _multiple inheritance_ from `GrammarCoverageFuzzer` and `ProbabilisticGrammarFuzzer` to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution**.  With multiple inheritance, this is fairly easy; we just need to point the three methods to the right places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class ProbabilisticGrammarCoverageFuzzer(GrammarCoverageFuzzer, ProbabilisticGrammarFuzzer):\n",
    "    # Choose uncovered expansions first\n",
    "    def choose_node_expansion(self, node, possible_children):\n",
    "        return GrammarCoverageFuzzer.choose_node_expansion(self, node, possible_children)\n",
    "\n",
    "    # Among uncovered expansions, pick by (relative) probability\n",
    "    def choose_uncovered_node_expansion(self, node, possible_children):\n",
    "        return ProbabilisticGrammarFuzzer.choose_node_expansion(self, node, possible_children)\n",
    "    \n",
    "    # For covered nodes, pick by probability, too\n",
    "    def choose_covered_node_expansion(self, node, possible_children):\n",
    "        return ProbabilisticGrammarFuzzer.choose_node_expansion(self, node, possible_children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "In the first nine invocations, our fuzzer covers one digit after another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "cov_leaddigit_fuzzer = ProbabilisticGrammarCoverageFuzzer(PROBABILISTIC_EXPR_GRAMMAR, start_symbol=\"<leaddigit>\")\n",
    "print([cov_leaddigit_fuzzer.fuzz() for i in range(9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "After these, we again proceed by probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "trials = 10000\n",
    "\n",
    "count = {}\n",
    "for c in crange('0', '9'):\n",
    "    count[c] = 0\n",
    "\n",
    "for i in range(trials):\n",
    "    count[cov_leaddigit_fuzzer.fuzz()] += 1\n",
    "\n",
    "print([(digit, count[digit] / trials) for digit in count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Test: \\cite{Holler2012}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "_Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
