{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grammar-based Mutational Fuzzing\n",
    "Previously, we have learned about [mutational fuzzing](GreyboxFuzzer.ipynb), which generates new inputs by mutating seed inputs. Most mutational fuzzers represent inputs as a sequence of bytes and apply byte-level mutations to this byte sequence. Such byte-level mutations work great for compact file formats with a small number of structural constraints. However, most file formats impose a high-level structure on these byte sequences.\n",
    "\n",
    "Common components of a regular file are file header, data chunks, checksums, data fields, and meta data. Only if this file structure is correctly reflected will the file be accepted by the parser. Otherwise, the file is quickly rejected before reaching interesting parts in the program. It is not easy to generate valid files by [random fuzzing](Fuzzer.ipynb). For instance, only a tiniest proportion of random strings are valid PDF files or valid JPEG image files.\n",
    "\n",
    "Maybe we can start with a valid file and generate new valid files by small mutations applied to the original file? Indeed, this is the main insight of ([blackbox](MutationFuzzer.ipynb) and [greybox](GreyboxFuzzer.ipynb)) mutational fuzzing. However, many file formats are so complex that even small modifications lead to invalid inputs that are quickly rejected by the parser.\n",
    "\n",
    "In this chapter, we encode file formats as [grammars](Grammars.ipynb) and make the mutational fuzzer input-structure-aware. We investigate opportunities to inform the fuzzer about the validity of the generated inputs. Specifically, we explore dictionaries, grammars, structural mutators, and validity-based power schedules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "First, we [recall](GreyboxFuzzer.ipynb#Ingredients-for-Greybox-Fuzzing) a few basic ingredients for mutational fuzzers.\n",
    "* **Seed**. A seed is an input that is used by the fuzzer to generate new inputs by applying a sequence of mutations.\n",
    "* **Mutator**. A mutator implements a set of mutation operators that applied to an input produce a slightly modified input.\n",
    "* **PowerSchedule**. A power schedule assigns energy to a seed. A seed with higher energy is fuzzed more often throughout the fuzzing campaign.\n",
    "* **MutationFuzzer**. A mutational blackbox fuzzer generates inputs by mutating seeds in an initial population of inputs.\n",
    "* **GreyboxFuzzer**. A greybox fuzzer dynamically adds inputs to the population of seeds that increased coverage.\n",
    "* **FunctionCoverageRunner**. The function coverage runner collects coverage information for the execution of a given Python function.\n",
    "\n",
    "Let's try to get a feeling for these concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GreyboxFuzzer import Mutator, Seed, PowerSchedule, MutationFuzzer, GreyboxFuzzer\n",
    "from MutationFuzzer import FunctionCoverageRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command applies a mutation to the input \"Hello World\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mutator().mutate(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default power schedule assigns energy uniformly across all seeds. Let's check this.\n",
    "\n",
    "We choose 10k times from 3 seeds. We should choose each seed about a third of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = [Seed(\"A\"), Seed(\"B\"), Seed(\"C\")]\n",
    "schedule = PowerSchedule()\n",
    "hits = {\n",
    "    \"A\" : 0,\n",
    "    \"B\" : 0,\n",
    "    \"C\" : 0\n",
    "}\n",
    "\n",
    "for i in range(10000):\n",
    "    seed = schedule.choose(population)\n",
    "    hits[seed.data] += 1\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before explaining the function coverage runner, lets import Python's HTML parser as example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. and create a wrapper function that passes each input into a new parser object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_parser(inp):\n",
    "    parser = HTMLParser()\n",
    "    parser.feed(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FunctionCoverageRunner` constructor takes a Python `function` to execute. The function `run` takes an input, passes it on to the Python `function`, and collects the coverage information for this execution. The function `coverage()` returns a list of tuples `(function name, line number)` for each statement that has been covered in the Python `function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = FunctionCoverageRunner(my_parser)\n",
    "runner.run(\"Hello World\")\n",
    "cov = runner.coverage()\n",
    "\n",
    "list(cov)[:5] # Print 5 statements covered in HTMLParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzzer takes a seed population, mutator, and power schedule. Let's generate 5000 fuzz inputs starting with an \"empty\" seed corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "seed_input = \" \" # empty seed\n",
    "runner = FunctionCoverageRunner(my_parser)\n",
    "fuzzer = GreyboxFuzzer([seed_input], Mutator(), PowerSchedule())\n",
    "\n",
    "start = time.time()\n",
    "fuzzer.runs(runner, trials=n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"During this fuzzing campaign, we covered %d statements.\" % len(runner.coverage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary: Injecting Important Keywords\n",
    "Today, dictionaries are the main mechanism to inform a mutational fuzzer about important keywords in the input. \n",
    "\n",
    "To inform the fuzzer about important keywords, we extend our mutator to consider keywords from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictMutator(Mutator):\n",
    "    def __init__(self, dictionary):\n",
    "        super().__init__()\n",
    "        self.dictionary = dictionary\n",
    "        self.mutators.append(self.insert_from_dictionary)\n",
    "        \n",
    "    def insert_from_dictionary(self,s):\n",
    "        \"\"\"Returns s with a keyword from the dictionary inserted\"\"\"\n",
    "        pos = random.randint(0, len(s))\n",
    "        random_keyword = random.choice(self.dictionary)\n",
    "        return s[:pos] + random_keyword + s[pos:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to add a few HTML-tags and attributes and see the coverage of the fuzzer with the DictMutator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = FunctionCoverageRunner(my_parser)\n",
    "dict_mutator = DictMutator([\"<a>\",\"</a>\",\"<a/>\", \"='a'\"])\n",
    "dict_fuzzer = GreyboxFuzzer([seed_input], dict_mutator, PowerSchedule())\n",
    "\n",
    "start = time.time()\n",
    "dict_fuzzer.runs(runner, trials = n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, it takes longer. In our experience, this means more code is covered. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"During this fuzzing campaign, we covered %d statements.\" % len(runner.coverage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the fuzzers compare in terms of coverage over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Coverage import population_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dict_cov = population_coverage(dict_fuzzer.inputs, my_parser)\n",
    "_, fuzz_cov = population_coverage(fuzzer.inputs, my_parser)\n",
    "line_dict, = plt.plot(dict_cov, label=\"With Dictionary\")\n",
    "line_fuzz, = plt.plot(fuzz_cov, label=\"Without Dictionary\")\n",
    "plt.legend(handles=[line_dict, line_fuzz])\n",
    "plt.xlim(0,n)\n",
    "plt.title('Coverage over time')\n",
    "plt.xlabel('# of inputs')\n",
    "plt.ylabel('lines covered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\todo{Andreas: Section on mining keywords using parser-directed fuzzing or AUTOGRAM?}\n",
    "\n",
    "\n",
    "***Summary.*** Informing the fuzzer about important keywords already goes a long way towards achieving lots of coverage quickly.\n",
    "\n",
    "***Try it.*** Open this chapter as Jupyter notebook (e.g., [Resources]->[Edit as Notebook]), and add other HTML-related keywords to the dictionary in order to see whether the difference in coverage actually increases (given the same budget of 5k generated test inputs).\n",
    "\n",
    "***Read up.*** Micha≈Ç Zalewski, author of AFL, wrote several great blog posts on [making up grammars with a dictionary in hand](https://lcamtuf.blogspot.com/2015/01/afl-fuzz-making-up-grammar-with.html) and [pulling JPEGs out of thin air](https://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure-Aware Mutation of Valid Seeds\n",
    "While dictionaries are helpful to inject important keywords into seed inputs, they do not allow to maintain the structural integrity of the generated inputs. Instead, we need to make the fuzzer *aware of the input structure*. We can do this using [grammars](Grammars.ipynb). Our first approach [parses](Parser.ipynb) the seed inputs, disassembles them into input fragments, and generates new files by reassembling these fragments according to the rules of the grammar.\n",
    "\n",
    "\\todo{Andreas: LangFuzzer story.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate valid HTML inputs for our Python HTMLParser, we should first define a simple grammar. It allows to define HTML tags with attributes. Our context-free grammar does not require that opening and closing tags must match. However, we will see that such context-sensitive features can be maintained in the derived input fragments, and thus in the generated inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from Grammars import is_valid_grammar, srange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_TOKENS = {\"<id>\",\"<text>\"}\n",
    "\n",
    "XML_GRAMMAR = {\n",
    "    \"<start>\": [\"<xml-tree>\"],\n",
    "    \"<xml-tree>\": [\"<text>\",\n",
    "                   \"<xml-open-tag><xml-tree><xml-close-tag>\", \n",
    "                   \"<xml-openclose-tag>\", \n",
    "                   \"<xml-tree><xml-tree>\"],\n",
    "    \"<xml-open-tag>\":      [\"<<id>>\", \"<<id> <xml-attribute>>\"],\n",
    "    \"<xml-openclose-tag>\": [\"<<id>/>\", \"<<id> <xml-attribute>/>\"],\n",
    "    \"<xml-close-tag>\":     [\"</<id>>\"],\n",
    "    \"<xml-attribute>\" :    [\"<id>=<id>\", \"<xml-attribute> <xml-attribute>\"],\n",
    "    \"<id>\":                [\"<letter>\", \"<id><letter>\"],\n",
    "    \"<text>\" :             [\"<text><letter_space>\",\"<letter_space>\"],\n",
    "    \"<letter>\":            srange(string.ascii_letters + string.digits +\"\\\"\"+\"'\"+\".\"),\n",
    "    \"<letter_space>\":      srange(string.ascii_letters + string.digits +\"\\\"\"+\"'\"+\" \"+\"\\t\"),\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(XML_GRAMMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to derive the structure from an input, we use the [Earley parser](Parser.ipynb#Parsing-Context-Free-Grammars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import EarleyParser\n",
    "from GrammarFuzzer import display_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the parser on a simple HTML input and display all possible parse trees. A *parse tree* represents the input structure according to the given grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS)\n",
    "\n",
    "for tree in parser.parse(\"<html>Text</html>\"):\n",
    "    display_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the input starts with an opening tag, contains some text, and ends with a closing tag. Excellent. This is a structure that we can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Fragment Pool\n",
    "We are now ready to implement our first input-structure-aware mutator. Let's initialize the mutator with the dictionary `fragments` representing the empty fragment pool. It contains a key for each symbol in the grammar (and the empty set as value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(Mutator):\n",
    "    def __init__(self, parser):\n",
    "        \"\"\"Initialize empty fragment pool and add parser\"\"\"\n",
    "        self.parser = parser\n",
    "        self.fragments = {k: [] for k in self.parser.cgrammar}\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FragmentMutator` adds fragements recursively. A *fragment* is a subtree in the parse tree and consists of the symbol of the current node and child nodes (i.e., descendant fragments). We can exclude fragments starting with symbols that are tokens, terminals, or not part of the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def add_fragment(self, fragment):\n",
    "        \"\"\"Recursively adds fragments to the fragment pool\"\"\"\n",
    "        (symbol, children) = fragment\n",
    "        if not self.is_excluded(symbol):\n",
    "            self.fragments[symbol].append(fragment)\n",
    "            for subfragment in children:\n",
    "                self.add_fragment(subfragment)\n",
    "        \n",
    "    def is_excluded(self, symbol):\n",
    "        \"\"\"Returns true if a fragment starting with a specific\n",
    "           symbol and all its decendents can be excluded\"\"\"\n",
    "        return ((not symbol in self.parser.grammar()) or\n",
    "                symbol in self.parser.tokens or\n",
    "                symbol in terminals(self.parser.grammar()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing can take a long time, particularly if there is too much ambiguity during the parsing. In order to maintain the efficiency of mutational fuzzing, we will limit the parsing time to 200ms. To implement this parser timeout, we define and register a `timeout` function as signal handler for `SIGALRM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timeout(Exception): pass\n",
    "def timeout(signum, frame): \n",
    "    raise Timeout()\n",
    "    \n",
    "signal.signal(signal.SIGALRM, timeout)\n",
    "\"Function 'timeout' registered as handler for signal 'SIGALRM'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `add_to_fragment_pool` parses a seed (no longer than 200ms) and adds all its fragments to the fragment pool. If the parsing the `seed` was successful, the attribute `seed.has_structure` is set to `True`. Otherwise, it is set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def add_to_fragment_pool(self, seed):\n",
    "        \"\"\"Adds all fragments of a seed to the fragment pool\"\"\"\n",
    "        try: # only allow quick parsing of 200ms max\n",
    "            signal.setitimer(signal.ITIMER_REAL, 0.2)\n",
    "            seed.structure = next(self.parser.parse(seed.data))\n",
    "            signal.setitimer(signal.ITIMER_REAL, 0)\n",
    "            \n",
    "            self.add_fragment(seed.structure)\n",
    "            seed.has_structure = True\n",
    "        except (SyntaxError, Timeout):\n",
    "            seed.has_structure = False\n",
    "            signal.setitimer(signal.ITIMER_REAL, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how `FragmentMutator` fills the fragment pool for a simple HTML seed input. We initialize mutator with the `EarleyParser` which itself is initialized with our `XML_GRAMMAR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import tree_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seed = Seed(\"<html><header><title>Hello</title></header><body>World<br/></body></html>\")\n",
    "fragment_mutator = FragmentMutator(EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))\n",
    "fragment_mutator.add_to_fragment_pool(valid_seed)\n",
    "\n",
    "for key in fragment_mutator.fragments:\n",
    "    print(key)\n",
    "    for f in fragment_mutator.fragments[key]:\n",
    "        print(\"|-%s\" % tree_to_string(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many symbols in the grammar, we have collected a number of fragments. There are several open and closing tags and several interesting fragments starting with the `xml-tree` symbol.\n",
    "\n",
    "***Summary***. For each interesting symbol in the grammar, the `FragmentMutator` has a set of fragments. These fragments are extracted by first parsing the inputs to be mutated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragment-based Mutation\n",
    "We can use the fragments in the fragment pool to generate new inputs. Every seed that is being mutated is disassembled into fragments, and memoized -- i.e., disassembled only the first time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def __init__(self, parser):\n",
    "        \"\"\"Initialize mutators\"\"\"\n",
    "        super().__init__(parser)\n",
    "        self.seen_seeds = []\n",
    "\n",
    "    def mutate(self, seed):\n",
    "        \"\"\"Implement structure-aware mutation. Memoize seeds.\"\"\"\n",
    "        if not seed in self.seen_seeds:\n",
    "            self.seen_seeds.append(seed)\n",
    "            self.add_to_fragment_pool(seed)\n",
    "        return super().mutate(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first structural mutation operator is `swap_fragments` which choses a random fragment in the given seed and substitutes it with a random fragment from the pool. We make sure that both fragments start with the same symbol. For instance, we may swap a closing tag in the seed HTML by another closing tag from the fragment pool.\n",
    "\n",
    "In order to choose a random fragment, the mutator counts all fragments (`n_count`) below the root fragment associated with the start-symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def count_nodes(self, fragment):\n",
    "        \"\"\"Returns the number of nodes in the fragment\"\"\"\n",
    "        symbol, children = fragment\n",
    "        if self.is_excluded(symbol):\n",
    "            return 0\n",
    "        return 1 + sum(map(self.count_nodes, children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to swap the chosen fragment -- identified using the \"global\" variable `self.to_swap` -- the seed's parse tree is traversed recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def recursive_swap(self, fragment):\n",
    "        \"\"\"Recursively finds the fragment to swap.\"\"\"\n",
    "        symbol, children = fragment\n",
    "        if self.is_excluded(symbol):\n",
    "            return symbol, children\n",
    "\n",
    "        self.to_swap -= 1\n",
    "        if self.to_swap == 0: \n",
    "            return random.choice(list(self.fragments[symbol]))\n",
    "        return symbol, list(map(self.recursive_swap, children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our structural mutator chooses a random number between 2 (i.e., excluding the `start` symbol) and the total number of fragments (`n_count`) and uses the recursive swapping to generate the new fragment. The new fragment is serialized as string and returned as new seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def __init__(self, parser):\n",
    "        super().__init__(parser)\n",
    "        self.mutators = [self.swap_fragment]\n",
    "          \n",
    "    def swap_fragment(self, seed):\n",
    "        \"\"\"Substitutes a random fragment with another with the same symbol\"\"\"\n",
    "        if seed.has_structure:\n",
    "            n_nodes = self.count_nodes(seed.structure)\n",
    "            self.to_swap = random.randint(2, n_nodes)\n",
    "            new_structure = self.recursive_swap(seed.structure)\n",
    "            \n",
    "            new_seed = Seed(tree_to_string(new_structure))\n",
    "            new_seed.has_structure = True\n",
    "            new_seed.structure = new_structure\n",
    "            return new_seed\n",
    "        return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seed = Seed(\"<html><header><title>Hello</title></header><body>World<br/></body></html>\")\n",
    "lf_mutator = FragmentMutator(parser)\n",
    "print(valid_seed)\n",
    "lf_mutator.mutate(valid_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, one fragment has been substituted by another. \n",
    "\n",
    "We can use a similar recursive traversal to *remove* a random fragment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def recursive_delete(self, fragment):\n",
    "        \"\"\"Recursively finds the fragment to delete\"\"\"\n",
    "        symbol, children = fragment\n",
    "        if self.is_excluded(symbol):\n",
    "            return symbol, children\n",
    "\n",
    "        self.to_delete -= 1\n",
    "        if self.to_delete == 0: \n",
    "            return symbol, []\n",
    "        return symbol, list(map(self.recursive_delete, children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also define the corresponding structural deletion operator, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FragmentMutator(FragmentMutator):\n",
    "    def __init__(self, parser):\n",
    "        super().__init__(parser)\n",
    "        self.mutators.append(self.delete_fragment)\n",
    "    \n",
    "    def delete_fragment(self, seed):\n",
    "        \"\"\"Deletes a random fragment\"\"\"\n",
    "        if seed.has_structure:\n",
    "            n_nodes = self.count_nodes(seed.structure)\n",
    "            self.to_delete = random.randint(2, n_nodes)\n",
    "            new_structure = self.recursive_delete(seed.structure)\n",
    "            \n",
    "            new_seed = Seed(tree_to_string(new_structure))\n",
    "            new_seed.has_structure = True\n",
    "            new_seed.structure = new_structure\n",
    "            # do not return an empty new_seed\n",
    "            if not new_seed.data: return seed\n",
    "            else: return new_seed\n",
    "        return seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary***. We now have all ingredients for structure-aware fuzzing. Our mutator disassembles all seeds into fragments, which are then added to the fragment pool. Our mutator swaps random fragments in a given seed with fragments of the same type. And our mutator deletes random fragments in a given seed. This allows to maintain a high degree of validity for the generated inputs w.r.t. the given grammar.\n",
    "\n",
    "***Try it***. Try adding other structural mutation operators. How would an *add-operator* know the position in a given seed file, where it is okay to add a fragment starting with a certain symbol?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragment-based Fuzzing\n",
    "We can now define a input-structure aware fuzzer as pioneered in LangFuzzer. To implement LangFuzz, we modify our [blackbox mutational fuzzer](GreyboxFuzzer.ipynb#Blackbox-Mutation-based-Fuzzer) to stack up to four structural mutations.\n",
    "\n",
    "\\todo{Andreas: More about LangFuzzer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangFuzzer(MutationFuzzer):\n",
    "    def create_candidate(self):\n",
    "        \"\"\"Returns an input generated by fuzzing a seed in the population\"\"\"\n",
    "        candidate = self.schedule.choose(self.population)\n",
    "        trials = random.randint(1,4)\n",
    "        for i in range(trials):\n",
    "            candidate = self.mutator.mutate(candidate)\n",
    "        return candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's take our first input-structure aware fuzzer for a spin. Being careful, we set n=300 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300\n",
    "runner = FunctionCoverageRunner(my_parser)\n",
    "mutator = FragmentMutator(EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))\n",
    "schedule = PowerSchedule()\n",
    "\n",
    "langFuzzer = LangFuzzer([valid_seed.data], mutator, schedule)\n",
    "\n",
    "start = time.time()\n",
    "langFuzzer.runs(runner, trials = n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took LangFuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe, structural mutation is *sooo very slow*. This is despite our time budget of 200ms for parsing. In contrast, our blackbox fuzzer alone can generate about 10k inputs per second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = FunctionCoverageRunner(my_parser)\n",
    "mutator = Mutator()\n",
    "schedule = PowerSchedule()\n",
    "\n",
    "blackFuzzer = MutationFuzzer([valid_seed.data], mutator, schedule)\n",
    "\n",
    "start = time.time()\n",
    "blackFuzzer.runs(runner, trials = n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took a blackbox fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, our blackbox fuzzer is done in the blink of an eye.\n",
    "\n",
    "***Try it***. We can deal with this overhead using [deferred parsing](https://arxiv.org/abs/1811.09447). Instead of wasting time in the beginning of the fuzzing campaign when a byte-level mutator would make efficient progress, deferred parsing suggests to invest time in structural mutation only later in the fuzzing campaign when it becomes viable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox_coverage = len(runner.coverage())\n",
    "\"During this fuzzing campaign, the blackbox fuzzer covered %d statements.\" % blackbox_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print some stats for our fuzzing campaigns. Since we'll need to print stats more often later, we should wrap this into a function. In order to measure coverage, we import the [population_coverage](Coverage.ipynb#Coverage-of-Basic-Fuzzing) function. It takes a set of inputs and a Python function, executes the inputs on that function and collects coverage information. Specifically, it returns a tuple `(all_coverage, cumulative_coverage)` where `all_coverage` is the set of statements covered by all inputs, and `cumulative_coverage` is the number of statements covered as the number of executed inputs increases. We are just interested in the latter to plot coverage over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Coverage import population_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(fuzzer, parser):\n",
    "    coverage, _ = population_coverage(fuzzer.inputs, my_parser)\n",
    "    \n",
    "    has_structure = 0\n",
    "    for seed in fuzzer.inputs:\n",
    "        # reuse memoized information\n",
    "        if hasattr(seed, \"has_structure\"):\n",
    "            if seed.has_structure: \n",
    "                has_structure += 1\n",
    "        else:\n",
    "            if isinstance(seed, str):\n",
    "                seed = Seed(seed)\n",
    "            try:\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0.2)\n",
    "                next(parser.parse(seed.data))\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0)\n",
    "                has_structure += 1\n",
    "            except (SyntaxError, Timeout):\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0)\n",
    "        \n",
    "    print(\"From the %d generated inputs, %d (%0.2f%%) can be parsed.\\n\"\n",
    "          \"In total, %d statements are covered.\" % (\n",
    "        len(fuzzer.inputs),\n",
    "        has_structure,\n",
    "        100 * has_structure / len(fuzzer.inputs),\n",
    "        len(coverage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LangFuzzer, let's see how many of the inputs generated by LangFuzz are valid (i.e., parsable) and how many statements were covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(langFuzzer, EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the stats for the mutational fuzzer that uses only byte-level mutation (and no grammars)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(blackFuzzer, EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary***. Our fragment-level blackbox fuzzer (LangFuzzer) generates *more valid inputs* but achieves *less code coverage* than a fuzzer with our byte-level fuzzer. So, there is some value in generating inputs that do not stick to the provided grammar. \n",
    "\n",
    "***Read up***. Learn more about fragment-based structural fuzzing in the original LangFuzz paper: \"[Fuzzing with Code Fragments](https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final73.pdf)\" by Holler, Herzig, and Zeller, USENIX Security 2012.\n",
    "\n",
    "In the following we integrate fragment-level blackbox fuzzing (LangFuzz-style) with [byte-level greybox fuzzing](GreyboxFuzzer.ipynb#Greybox-Mutation-based-Fuzzer) (AFL-style). The additional coverage-feedback might allow us to increase code coverage more quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with Greybox Fuzzing\n",
    "A [greybox fuzzer](GreyboxFuzzer.ipynb#Greybox-Mutation-based-Fuzzer) adds to the seed population all generated inputs which increase code coverage. Inputs are generated in two stages, stacking up to four structural mutations and up to 32 byte-level mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureAwareGreyboxFuzzer(GreyboxFuzzer):\n",
    "    def __init__(self, seeds, byte_mutator, tree_mutator, schedule):\n",
    "        super().__init__(seeds, byte_mutator, schedule)\n",
    "        self.tree_mutator = tree_mutator\n",
    "    \n",
    "    def create_candidate(self):\n",
    "        \"\"\"Returns an input generated by structural mutation of a seed in the population\"\"\"\n",
    "        seed = self.schedule.choose(self.population)\n",
    "        \n",
    "        # Structural mutation\n",
    "        trials = random.randint(0,4)\n",
    "        for i in range(trials):\n",
    "            seed = self.tree_mutator.mutate(seed)\n",
    "        \n",
    "        # Byte-level mutation\n",
    "        candidate = seed.data\n",
    "        if trials == 0 or not seed.has_structure or 1 == random.randint(0, 1):\n",
    "            dumb_trials = min(len(seed.data), 1 << random.randint(1,5))\n",
    "            for i in range(dumb_trials):\n",
    "                candidate = self.mutator.mutate(candidate)\n",
    "        return candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our integrated fuzzer with the [standard byte-level mutator](GreyboxFuzzer.ipynb#Mutator-and-Seed) and our [fragment-based structural mutator](#Fragment-based-Mutation) that was introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = FunctionCoverageRunner(my_parser)\n",
    "byte_mutator = Mutator()\n",
    "tree_mutator = FragmentMutator(EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))\n",
    "schedule = PowerSchedule()\n",
    "\n",
    "structureFuzzer = StructureAwareGreyboxFuzzer([valid_seed.data], byte_mutator, tree_mutator, schedule)\n",
    "\n",
    "start = time.time()\n",
    "structureFuzzer.runs(runner, trials = n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the input structure-aware greybox fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(structureFuzzer, EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary***. Our structural greybox fuzzer \n",
    "* runs faster than the fragment-based LangFuzzer,\n",
    "* achieves more coverage than both, the fragment-based LangFuzzer and the vanilla blackbox mutational fuzzer, and\n",
    "* generates less valid inputs than even the vanilla blackbox mutational fuzzer.\n",
    "\n",
    "However, most inputs that are added as seeds are *invalid* w.r.t. our given grammar. Yet, in order to apply our fragment-based mutators, we need it to parse the seed successfully. Otherwise, the entire fragment-based approach becomes useless.\n",
    "\n",
    "*How can we derive structure from (invalid) seeds that cannot be parsed successfully?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure-Aware Mutation of Invalid Seeds\n",
    "The idea of region-based mutation was first explored with the [AFLSmart](https://github.com/aflsmart/aflsmart) structural greybox fuzzer \\cite{aflsmart}. AFLSmart implements byte-level, fragment-based, and region-based mutation as well as validity-based power schedules. In this section, we define *region-based mutators*, where a *region* is a consecutive sequence of bytes in the input that can be associated with a symbol in the grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Symbol Regions\n",
    "The function `chart_parse` of the [Earley parser](Parser.ipynb#The-Parsing-Algorithm) produces a parse table for a string. For each letter in the string, this table gives the potential symbol and a *region* of neighboring letters that might belong to the same symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "invalid_seed = Seed(\"<html><body><i>World</i><br/>>/body></html>\")\n",
    "parser = EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS)\n",
    "table = parser.chart_parse(invalid_seed.data, parser.start_symbol())\n",
    "for column in table:\n",
    "    print(column)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of columns in this table that are associated with potential symbols correspond to the number of letters that could be parsed successfully. In other words, we can use this table to compute the longest parsable substring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in table if col.states]\n",
    "parsable = invalid_seed.data[:len(cols)-1]\n",
    "\n",
    "print(\"'%s'\" % invalid_seed)\n",
    "parsable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can compute the *degree of validity* for an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validity = 100 * len(parsable) / len(invalid_seed.data)\n",
    "\n",
    "\"%0.1f%% of the string can be parsed successfully.\" % validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary***. Unlike input fragments, input regions can be derived even if the parser fails to generate the entire parse tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region-based Mutation\n",
    "To fuzz invalid seeds, the region-based mutator associates symbols from the grammar with regions (i.e., indexed substrings) in the seed. The [overridden](GrammarGreyboxFuzzer.ipynb#Building-the-Fragment-Pool) function `add_to_fragment_pool` first tries to mine the fragments from the seed. If this fails, the region mutator uses [Earley parser](Parser.ipynb#The-Parsing-Algorithm) to derive the parse table. For each column (i.e., letter), it extracts the symbols and corresponding regions. This allows the mutator to store the set of regions with each symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionMutator(FragmentMutator):\n",
    "    def add_to_fragment_pool(self, seed):\n",
    "        \"\"\"Mark fragments and regions in a seed file\"\"\"\n",
    "        super().add_to_fragment_pool(seed)\n",
    "        if not seed.has_structure:\n",
    "            try:\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0.2) # set 200ms timeout\n",
    "                seed.regions = {k: set() for k in self.parser.cgrammar}\n",
    "                for column in self.parser.chart_parse(seed.data, self.parser.start_symbol()):\n",
    "                    for state in column.states:\n",
    "                        if (not self.is_excluded(state.name) and\n",
    "                                state.e_col.index - state.s_col.index > 1 and\n",
    "                                state.finished()):\n",
    "                            seed.regions[state.name].add((state.s_col.index, state.e_col.index))\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0) # cancel timeout\n",
    "                seed.has_regions = True\n",
    "            except Timeout:\n",
    "                seed.has_regions = False\n",
    "        else:\n",
    "            seed.has_regions = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how these regions look like for our invalid seed. A region consists of a start and end index in the seed string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutator = RegionMutator(parser)\n",
    "mutator.add_to_fragment_pool(invalid_seed)\n",
    "for symbol in invalid_seed.regions:\n",
    "    print(symbol)\n",
    "    for (s, e) in invalid_seed.regions[symbol]:\n",
    "        print(\"|-(%d,%d) : %s\" % (s, e, invalid_seed.data[s:e]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which regions in the seed belong to which symbol, we can define region-based swap and delete operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionMutator(RegionMutator):\n",
    "    def swap_fragment(self, seed):\n",
    "        \"\"\"Chooses a random region and swaps it with a fragment\n",
    "           that starts with the same symbol\"\"\"\n",
    "        if not seed.has_structure and seed.has_regions:\n",
    "            regions = [r for r in seed.regions\n",
    "                         if (len(seed.regions[r]) > 0 and\n",
    "                            len(self.fragments[r]) > 0)]\n",
    "            if len(regions) == 0: return seed\n",
    "                \n",
    "            key = random.choice(list(regions))\n",
    "            s, e = random.choice(list(seed.regions[key]))\n",
    "            swap_structure = random.choice(self.fragments[key])\n",
    "            swap_string = tree_to_string(swap_structure)\n",
    "            new_seed = Seed(seed.data[:s] + swap_string + seed.data[e:])\n",
    "            new_seed.has_structure = False\n",
    "            new_seed.has_regions = False\n",
    "            return new_seed\n",
    "        else:\n",
    "            return super().swap_fragment(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionMutator(RegionMutator):\n",
    "    def delete_fragment(self, seed):\n",
    "        \"\"\"Deletes a random region\"\"\"\n",
    "        if not seed.has_structure and seed.has_regions:\n",
    "            regions = [r for r in seed.regions\n",
    "                         if len(seed.regions[r]) > 0]\n",
    "            if len(regions) == 0: return seed\n",
    "\n",
    "            key = random.choice(list(regions))\n",
    "            s, e = (0, 0)\n",
    "            while (e - s < 2):\n",
    "                s, e = random.choice(list(seed.regions[key]))\n",
    "            new_seed = Seed(seed.data[:s] + seed.data[e:])\n",
    "            new_seed.has_structure = False\n",
    "            new_seed.has_regions = False\n",
    "            return new_seed\n",
    "        else:\n",
    "            return super().delete_fragment(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our new region-based mutator. We add a simple, valid seed to the fragment pool and attempt to mutate the invalid seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_seed = Seed(\"<b>Text</b>\")\n",
    "mutator = RegionMutator(parser)\n",
    "mutator.add_to_fragment_pool(simple_seed)\n",
    "\n",
    "print(invalid_seed)\n",
    "mutator.mutate(invalid_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary***. We can use the Earley parser to generate a parse table and assign regions in the input to symbols in the grammar. Our region mutators can substitute these region with fragments from the fragment pool that start with the same symbol, or delete these regions entirely.\n",
    "\n",
    "***Try it***. Implement a region pool (similar to the fragment pool) and a `swap_region` mutator.\n",
    "You can execute your own code by opening this chapter as Jupyter notebook: [Resources]->[Edit as Notebook]. Then [Kernel]->[Restart & Run All]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region-based Fuzzing\n",
    "Let's try our shiny new region mutator by integrating it with our [structure-aware greybox fuzzer](#Integration-with-Greybox-Fuzzing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = FunctionCoverageRunner(my_parser)\n",
    "byte_mutator = Mutator()\n",
    "tree_mutator = RegionMutator(EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))\n",
    "schedule = PowerSchedule()\n",
    "\n",
    "regionFuzzer = StructureAwareGreyboxFuzzer([valid_seed.data], byte_mutator, tree_mutator, schedule)\n",
    "\n",
    "start = time.time()\n",
    "regionFuzzer.runs(runner, trials = n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the structural greybox fuzzer with region mutator\\\n",
    " %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the structural greybox fuzzer with region-based mutator is slower than the [fragment-based mutator alone](#Fragment-based-Fuzzing). This is because region-based structural mutation is applicable for *all seeds*. In contrast, fragment-based mutators were applicable only for tiny number of parsable seeds. Otherwise, only (very efficient) byte-level mutators were applied.\n",
    "\n",
    "Let's also print the average degree of validity for the seeds in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_more_stats(fuzzer, parser):\n",
    "    print_stats(fuzzer, parser)\n",
    "    validity = 0\n",
    "    total = 0\n",
    "    for seed in fuzzer.population:\n",
    "        if not seed.data: continue\n",
    "        table = parser.chart_parse(seed.data, parser.start_symbol())\n",
    "        cols = [col for col in table if col.states]\n",
    "        parsable = invalid_seed.data[:len(cols)-1]\n",
    "        validity += len(parsable) / len(seed.data)\n",
    "        total += 1\n",
    "    print(\"On average, %0.1f%% of a seed in the population can be successfully parsed.\" % (100 * validity / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_more_stats(regionFuzzer, parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary***. Compared to fragment-based mutation, a greybox fuzzer with region-based mutation achieves *higher coverage* but generates a *smaller number of valid inputs*. The higher coverage is explained by leveraging at least *some* structure for seeds that cannot be parsed successfully.\n",
    "\n",
    "How do we address the low (degree of) validity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validity-based Power Schedule\n",
    "A validity-based power schedule assigns more [energy](GreyboxFuzzer.ipynb#Power-Schedules) to seeds that have a higher degree of validity.\n",
    "\n",
    "In other words, the fuzzer spends more time fuzzing seeds that are more valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class AFLSmartSchedule(PowerSchedule):\n",
    "    \n",
    "    def __init__(self, parser, exponent):\n",
    "        self.parser = parser\n",
    "        self.exponent = exponent\n",
    "    \n",
    "    def parsable(self, seed):\n",
    "        \"\"\"Returns the substring that is parsable\"\"\"\n",
    "        table = self.parser.chart_parse(seed.data, parser.start_symbol())\n",
    "        cols = [col for col in table if col.states]\n",
    "        return seed.data[:len(cols)-1]\n",
    "    \n",
    "    def degree_of_validity(self, seed):\n",
    "        \"\"\"Returns the proportion of a seed that is parsable\"\"\"\n",
    "        if hasattr(seed, \"validity\"): return seed.validity\n",
    "        seed.validity = (len(self.parsable(seed)) / len(seed.data)\n",
    "                         if len(seed.data) > 0 else 0)\n",
    "        return seed.validity\n",
    "    \n",
    "    def assignEnergy(self, population):\n",
    "        \"\"\"Assign exponential energy proportional to degree of validity\"\"\"\n",
    "        for seed in population:\n",
    "            seed.energy = ((self.degree_of_validity(seed) / math.log(len(seed.data))) ** self.exponent\n",
    "                           if len(seed.data) > 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with the degree of validity by passing in a valid seed .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_schedule = AFLSmartSchedule(parser, 1)\n",
    "print(\"%11s: %s\" % (\"Entire seed\", simple_seed))\n",
    "print(\"%11s: %s\" % (\"Parsable\", smart_schedule.parsable(simple_seed)))\n",
    "\n",
    "\"Degree of validity: %0.2f%%\" % (100 * smart_schedule.degree_of_validity(simple_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. and an invalid seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%11s: %s\" % (\"Entire seed\", invalid_seed))\n",
    "print(\"%11s: %s\" % (\"Parsable\", smart_schedule.parsable(invalid_seed)))\n",
    "\n",
    "\"Degree of validity: %0.2f%%\" % (100 * smart_schedule.degree_of_validity(invalid_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. We can compute the degree of validity as the proportion of the string that can be parsed. \n",
    "\n",
    "Let's plug the validity-based power schedule into the structure-aware greybox fuzzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = FunctionCoverageRunner(my_parser)\n",
    "byte_mutator = Mutator()\n",
    "tree_mutator = RegionMutator(EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))\n",
    "schedule = AFLSmartSchedule(parser, 1)\n",
    "\n",
    "aflsmart = StructureAwareGreyboxFuzzer([valid_seed.data], byte_mutator, tree_mutator, schedule)\n",
    "\n",
    "start = time.time()\n",
    "aflsmart.runs(runner, trials = n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took AFLSmart %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_more_stats(aflsmart, parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary***. Indeed, by spending more time fuzzing seeds with a higher degree of validity, we also generate inputs with a higher degree of validity. More inputs are entirely valid w.r.t. the given grammar.\n",
    "\n",
    "***Read up***. Learn more about region-based fuzzing, deferred parsing, and validity-based schedules in the original AFLSmart paper: \"[Smart Greybox Fuzzing](https://arxiv.org/abs/1811.09447)\" by Pham et al.. Download and improve AFLSmart: [https://github.com/aflsmart/aflsmart](https://github.com/aflsmart/aflsmart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining Seeds From Code Repositories\n",
    "\\todo{Andreas}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "By adjusting the mutator and power schedule, we can improve the validity of the generated inputs.\n",
    "* A **dictionary** is useful to inject important keywords into the generated inputs.\n",
    "* **Fragment-based mutation** first disassembles seeds into fragments, and reassambles these fragments to generate new inputs. A *fragment* is a subtree in the seed's parse tree. However, fragment-based mutation requires that the seeds can be parsed successfully, which may not be true for seeds discovered by a coverage-based greybox fuzzer.\n",
    "* **Region-based mutation** marks regions in the input as belonging to a certain symbol in the grammar. For instance, it may identify a substring '</a>' as closing tag. These regions can than be deleted or substituted by fragments or regions belonging to the same symbol. Unlike fragment-based mutation, region-based mutation is applicable to *all* seeds -- even those that can be parsed only partially. However, the degree of validity is still quite low for the generated inputs.\n",
    "* A **validity-based power schedule** invests more energy into seeds with a higher degree of validity. The inputs that are generated also have a higher degree of validity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "* In the [chapter on evolutionary fuzzing](EvoGrammarFuzzer.ipynb), we discuss how to systematically evolve a population of inputs through mutation and crossover operations (as discussed in this chapter) to achieve a specific goal such as code coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background\n",
    "\n",
    "* **More about fragment-based mutation (LangFuzz)**: Christian Holler, Kim Herzig, Andreas Zeller. 2012. [Fuzzing with Code Fragments](https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final73.pdf), USENIX Security\n",
    "* **More about smart greybox fuzzing ([AFLSmart](https://github.com/aflsmart/aflsmart))** Van-Thuan Pham, Marcel B√∂hme, Andrew E. Santosa, Alexandru RƒÉzvan CƒÉciulescu, Abhik Roychoudhury. 2019. [Smart Greybox Fuzzing](https://arxiv.org/abs/1811.09447). ArXiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "\\todo{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** \\todo{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "With these changes, our `LangFuzzer2` is able to use the pool of fragments when necessary, but can rely on the grammar when the pool is not sufficient."
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
